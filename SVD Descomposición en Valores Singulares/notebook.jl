### A Pluto.jl notebook ###
# v0.20.3

using Markdown
using InteractiveUtils

# â•”â•â•¡ 701241c2-322f-45ca-b17d-437cf32a7ff3
using LinearAlgebra

# â•”â•â•¡ a58e9c22-51a1-11f0-0fc0-914efb421b18
md"""
# CÃ¡lculo NumÃ©rico de la SVD: Algoritmo de Golubâ€“Kahan

## Ãndice
1. Objetivos
1. IntroducciÃ³n
1. Fundamentos teÃ³ricos
3. Algoritmos
"""

# â•”â•â•¡ 11b2ebb7-626e-49c1-a294-c9b834c73bdb
md"
## Objetivos

Explicar y analizar detalladamente el algoritmo numÃ©rico para calcular la descomposiciÃ³n en valores singulares (SVD), con Ã©nfasis en el enfoque de Golubâ€“Kahan basado en la reducciÃ³n bidiagonal y la iteraciÃ³n QR implÃ­cita.

* Exponer las conexiones teÃ³ricas entre la SVD y los problemas de autovalores simÃ©tricos,
* analizar el comportamiento numÃ©rico del algoritmo clÃ¡sico frente a mÃ©todos mal condicionados,
* implementar y visualizar los pasos clave del algoritmo de Golubâ€“Kahan,
* discutir la eficiencia computacional y estrategias prÃ¡cticas.

En otro trabajo se puede aplicar la SVD computada numÃ©ricamente a un problema prÃ¡ctico.

## IntroducciÃ³n 

La descomposiciÃ³n en valores singulares (SVD) es una de las herramientas mÃ¡s poderosas y versÃ¡tiles del Ã¡lgebra lineal numÃ©rica.
No solo existe para cualquier matriz y proporciona informaciÃ³n estructural sobre ella â€”como su rango, condiciÃ³n y modos principales de acciÃ³nâ€”, sino que tambiÃ©n constituye la base de aplicaciones fundamentales en anÃ¡lisis de datos, compresiÃ³n, mÃ©todos de mÃ­nimos cuadrados, y problemas inversos.

Desde el punto de vista computacional, calcular la SVD de una matriz general $\in \mathbb{R}^{m \times n}$ de forma precisa y eficiente requiere mucho mÃ¡s que aplicar definiciones algebraicas. De hecho, formar matrices como $A^T A$ puede llevar a errores numÃ©ricos significativos. Para abordar este desafÃ­o, Golub y Kahan propusieron en 1965 un algoritmo robusto y eficiente basado en dos pasos clave:

1. **ReducciÃ³n bidiagonal de $A$** mediante transformaciones de Householder.
2. **DiagonalizaciÃ³n de la matriz bidiagonal** resultante usando una iteraciÃ³n QR adaptada, que opera de forma implÃ­cita sobre $B^T B$, sin construirla explÃ­citamente.

Este notebook estÃ¡ dedicado al estudio detallado de este algoritmo. Nuestro objetivo no es solo entender cÃ³mo se implementa, sino por quÃ© funciona, cÃ³mo se conecta con los problemas simÃ©tricos de autovalores, y quÃ© garantÃ­as numÃ©ricas ofrece.

A lo largo de este recorrido, desarrollaremos teorÃ­a, visualizaremos ejemplos pequeÃ±os y construiremos bloques de cÃ³digo que ilustran cada etapa del proceso. Este anÃ¡lisis estÃ¡ inspirado en la secciÃ³n 8.6 del libro *Matrix Computations*, de Golub y Van Loan, una referencia clÃ¡sica en el Ã¡rea.

> **Requisitos previos**: se asume familiaridad con transformaciones ortogonales (Householder, Givens), descomposiciÃ³n QR, y problemas de autovalores simÃ©tricos.

---
"

# â•”â•â•¡ 6b68d0ac-8118-44aa-940e-5a807217e562
md"
## Fundamentos teÃ³ricos de la SVD
DefiniciÃ³n y existencia

Propiedades bÃ¡sicas

SVD y matrices simÃ©tricas asociadas ?

Matriz aumentada simÃ©trica

Implicaciones algorÃ­tmicas

### ğŸŸ¢ DefiniciÃ³n y existencia de la SVD

Sea $A \in \mathbb{R}^{m \times n}$. La **descomposiciÃ³n en valores singulares (SVD)** de $A$ es una factorizaciÃ³n de la forma:

$A = U \Sigma V^T,$

donde
- las matrices $U \in \mathbb{R}^{m \times m}$ y $V \in \mathbb{R}^{n \times n}$ son ortogonales,
- la matriz $\Sigma \in \mathbb{R}^{m \times n}$ es diagonal rectangular con entradas no negativas en la diagonal:
  
$\Sigma = \begin{bmatrix}
\sigma_1 & & & \\
& & \ddots & \\
& & & \sigma_r \\
& & & & 0 \\
\end{bmatrix}, 
\quad \text{con } \sigma_1 \geq \sigma_2 \geq \cdots \geq \sigma_r > 0,$

y $r = \operatorname{rank}(A)$.

Las cantidades $\sigma_i$ se llaman **valores singulares** de $A$, y son Ãºnicos. Los vectores columna de $U$ y $V$ se llaman **vectores singulares izquierdos** y **derechos**, respectivamente.

#### â— Teorema de existencia

**Toda** matriz real \( A \in \mathbb{R}^{m \times n} \), sea cuadrada, rectangular, singular o no, **admite una descomposiciÃ³n SVD** como la descrita arriba.

Esto contrasta con la factorizaciÃ³n espectral, que solo existe para matrices simÃ©tricas.

#### ğŸ§  IntuiciÃ³n geomÃ©trica

La SVD describe la acciÃ³n de la matriz $A$ como una transformaciÃ³n que:

1. **Rota** el espacio fuente (a travÃ©s de $V^T$),
2. **Escala** en direcciones ortogonales (a travÃ©s de $\Sigma$),
3. **Rota** el espacio imagen (a travÃ©s de $U$).

En otras palabras, toda matriz real lineal puede descomponerse como una secuencia de rotaciones/reflexiones y escalamientos. Esta intuiciÃ³n es presentada de manera grÃ¡fica por Visual Kernel en el CapÃ­tulo 1 Visualize Different Matrices de su colecciÃ³n SEE Matrix.


"

# â•”â•â•¡ 56ef11c7-1b71-45f7-b286-38a932ac3dc4
md"""
### ğŸŸ¢ Propiedades bÃ¡sicas de la SVD

Dada la descomposiciÃ³n $A = U \Sigma V^T$ de una matriz $A \in \mathbb{R}^{m \times n}$, se cumplen las siguientes propiedades fundamentales:

#### ğŸ”¹ Ortogonalidad de los vectores singulares

- Las **columnas de $V$** (vectores singulares derechos) son autovectores de $A^T A$ y forman una base ortonormal de $\mathbb{R}^m$.
- Las **columnas de $U$** (vectores singulares izquierdos) son autovectores de $A A^T$ y forman una base ortonormal de $\mathbb{R}^n$.


#### ğŸ”¹ InterpretaciÃ³n de los valores singulares

- Los **autovalores** de $A^T A$ y $A A^T$ son exactamente $\sigma_i^2$.
- Los valores singulares $\sigma_i$ son los **autovalores positivos** de $A^T A$ o $A A^T$:
  $A^T A = V \Sigma^2 V^T, \quad A A^T = U \Sigma^2 U^T$
- Siempre se ordenan de forma no creciente:
  $\sigma_1 \geq \sigma_2 \geq \cdots \geq \sigma_r > 0$
- Se cumple que $\text{rank}(A) = r = \# \{ \sigma_i > 0 \}$.

#### ğŸ”¹ Normas y condiciÃ³n

- Norma 2:
  $\| A \|_2 = \sigma_1$
- Norma de Frobenius:
  $\| A \|_F = \left( \sum_{i=1}^r \sigma_i^2 \right)^{1/2}$
- NÃºmero de condiciÃ³n (si $A$ es cuadrada y de rango completo):
  $\kappa_2(A) = \frac{\sigma_1}{\sigma_r}$

#### ğŸ”¹ DescomposiciÃ³n como suma de rangos 1

La descomposiciÃ³n SVD permite representar cualquier matriz $A \in \mathbb{R}^{m \times n}$ como una **suma de matrices de rango 1**:

$A = \sum_{i=1}^r \sigma_i u_i v_i^T,$

donde $r = \operatorname{rank}(A)$, $u_i$ y $v_i$ son los vectores singulares izquierdo y derecho correspondientes al valor singular $\sigma_i$, cada tÃ©rmino $\sigma_i u_i v_i^T$ es una matriz de **rango 1**.

Esta forma revela que la SVD descompone $A$ como la suma de **modos bÃ¡sicos** ordenados por importancia (es decir, energÃ­a o norma).

##### ğŸ”¸ AproximaciÃ³n de rango bajo Ã³ptima

Una de las propiedades mÃ¡s poderosas de la SVD es que permite construir la **mejor aproximaciÃ³n de rango $k$** a $A$ en sentido de mÃ­nima distancia, tanto en norma 2 como en norma de Frobenius.

Para cualquier $k < r$, definimos:

$A_k = \sum_{i=1}^k \sigma_i u_i v_i^T,$

entonces se cumple $\| A - A_k \|_2 = \sigma_{k+1}$ y $\| A - A_k \|_F^2 = \sum_{i = k+1}^r \sigma_i^2$.

Este resultado se conoce como el **teorema de Eckartâ€“Young**, y afirma que $A_k$ es la mejor aproximaciÃ³n de $A$ por una matriz de rango $k$, en el sentido de ser la mÃ¡s cercana segÃºn dichas normas.


##### ğŸ“Œ Consecuencias prÃ¡cticas

- Los primeros tÃ©rminos de la SVD capturan la **estructura principal** de $A$.
- Los tÃ©rminos restantes pueden considerarse **ruido o detalles finos**.
- Este principio es la base de muchas tÃ©cnicas de **compresiÃ³n**, **reducciÃ³n de dimensionalidad** y **filtrado**.

Ejemplos tÃ­picos incluyen:
- Representar imÃ¡genes usando solo los primeros 10 valores singulares.
- Aproximar grandes matrices de datos con bajo rango efectivo.

"""

# â•”â•â•¡ dbb9e53d-bb68-4220-a32d-6c3ce32e274a
md"""
## Algoritmo de cÃ¡lculo de la SVD

* **OpciÃ³n 1**: $A^T A$
* * DefiniciÃ³n
* * Por quÃ© no se usa
* **OpciÃ³n 2**: Desde el punto de vista numÃ©rico, **Â¿cÃ³mo se calcula esta descomposiciÃ³n sin formar $A^T A$?**
* * Intro
* * Fundamentos teÃ³ricos
* * MÃ©todo de Golubâ€“Kahan

## ComparaciÃ³n / AnÃ¡lisis de los algoritmos
En la secciÃ³n anterior vimos que la SVD de una matriz $A \in \mathbb{R}^{m \times n}$ (con $m \geq n$) tiene la forma:

$A = U \Sigma V^T,$

donde $U$ y $V$ son ortogonales, y $\Sigma$ es una matriz diagonal rectangular con entradas no negativas.

"""

# â•”â•â•¡ 85c6df45-20ef-4db2-8703-ddf76166832e
md"""
## Algoritmos de cÃ¡lculo de la SVD

En esta secciÃ³n abordamos el problema de cÃ³mo calcular numÃ©ricamente la descomposiciÃ³n en valores singulares de una matriz $A \in \mathbb{R}^{m \times n}$. Aunque su existencia estÃ¡ garantizada teÃ³ricamente, el cÃ¡lculo efectivo de las matrices $U$, $\Sigma$ y $V$ requiere algoritmos cuidadosamente diseÃ±ados para asegurar estabilidad y eficiencia, especialmente cuando $A$ estÃ¡ mal condicionada o es de gran tamaÃ±o.

Comenzamos con el algoritmo clÃ¡sico, que se basa en la relaciÃ³n $A^T A = V \Sigma^2 V^T$ y permite obtener los valores y vectores singulares a partir de la descomposiciÃ³n espectral. Este mÃ©todo es Ãºtil para fines pedagÃ³gicos, pero es numÃ©ricamente inadecuado debido a su sensibilidad a errores de redondeo.

Luego presentaremos el mÃ©todo de Golubâ€“Kahan, que constituye la base de las implementaciones modernas de la SVD. Este enfoque evita formar $A^T A$ y combina una reducciÃ³n bidiagonal mediante transformaciones ortogonales con una versiÃ³n adaptada del algoritmo QR para matrices simÃ©tricas. Analizaremos este mÃ©todo en tres partes: una introducciÃ³n conceptual, los fundamentos teÃ³ricos que lo justifican, y una descripciÃ³n detallada del algoritmo.

Por Ãºltimo, exploraremos otras variantes relevantes como el mÃ©todo de Jacobi, los algoritmos divide-and-conquer, y algunas estrategias paralelas. Estas alternativas ofrecen ventajas particulares en tÃ©rminos de precisiÃ³n o rendimiento, y permiten comparar diferentes enfoques bajo distintas condiciones computacionales.


### Algoritmo clÃ¡sico

#### ğŸ”¹ DefiniciÃ³n

Dada una matriz $A \in \mathbb{R}^{m \times n}$, el producto $A^T A$ es una matriz simÃ©trica y semidefinida positiva de tamaÃ±o $n \times n$. Sus autovalores son no negativos, y sus autovectores son precisamente los vectores singulares derechos de $A$.

AdemÃ¡s, se cumple:

$A^T A = V \Sigma^2 V^T,$

lo que sugiere que una forma de obtener los valores singulares serÃ­a:

1. Formar $C = A^T A$,
2. Calcular sus autovalores $\lambda_i$,
3. Obtener $\sigma_i = \sqrt{\lambda_i}$,
4. Recuperar $U$ a partir de $AV = U \Sigma$.

#### ğŸ”¸ Â¿Por quÃ© no se usa este enfoque?

Aunque conceptualmente sencilla, esta estrategia es **numÃ©ricamente inestable**:

- **PÃ©rdida de precisiÃ³n:** el cÃ¡lculo de $A^T A$ **cuadra la condiciÃ³n** de $A$:
  $\kappa_2(A^T A) = \kappa_2(A)^2,$
  lo que magnifica errores cuando $A$ es mal condicionada.

- **Cancelaciones destructivas:** en aritmÃ©tica de punto flotante, calcular $A^T A$ puede eliminar informaciÃ³n valiosa contenida en $A$.

- **No preserva la estructura original:** operaciones como la bidiagonalizaciÃ³n sÃ­ preservan mejor las propiedades numÃ©ricas de $A$.

Por estas razones, los algoritmos modernos evitan formar explÃ­citamente $A^T A$, y utilizan en cambio mÃ©todos mÃ¡s estables, como el de **Golubâ€“Kahan**.


"""

# â•”â•â•¡ 74470dd1-eb43-4039-9d93-6bdf32768466
md"""
### MÃ©todo de Golubâ€“Kahan

El algoritmo de Golubâ€“Kahan para calcular la SVD de una matriz $A \in \mathbb{R}^{m \times n}$ (con $m \geq n$) consta de dos fases principales:

#### Paso a paso
##### ğŸ”¹ Paso 1: ReducciÃ³n bidiagonal

El primer paso transforma la matriz original $A$ en una matriz **bidiagonal** $B$, es decir, una matriz con ceros fuera de la diagonal y la superdiagonal:

$B = U_1^T A V_1$

Este paso se logra aplicando **transformaciones ortogonales de Householder** por la izquierda y la derecha, que eliminan progresivamente los elementos debajo de la diagonal y fuera de la banda bidiagonal.

La estructura resultante tiene la forma:

$B = \begin{bmatrix}
d_1 & f_1 &        &        & \\
    & d_2 & f_2    &        & \\
    &     & \ddots & \ddots & \\
    &     &        & d_{n-1} & f_{n-1} \\
    &     &        &        & d_n
\end{bmatrix}$

Donde $d_i$ son los elementos diagonales y $f_i$ los elementos de la superdiagonal.

Este paso convierte el problema general en uno estructurado, sin alterar los valores singulares, y ademÃ¡s **preserva la estabilidad numÃ©rica**.

##### ğŸ”¹ Paso 2: DiagonalizaciÃ³n bidiagonal (iteraciÃ³n QR simÃ©trica)

Una vez reducida $A$ a bidiagonal, el siguiente objetivo es transformar $B$ en una matriz **diagonal**, es decir, eliminar su superdiagonal sin perturbar la estructura.

Para esto se emplea una versiÃ³n adaptada del **algoritmo QR simÃ©trico con desplazamiento**. En lugar de formar $B^T B$ (que serÃ­a tridiagonal), se trabaja directamente sobre $B$ aplicando secuencias de **rotaciones de Givens** que eliminan progresivamente los elementos $f_i$.

Cada iteraciÃ³n consta de:

1. CÃ¡lculo de un **desplazamiento (shift)** aproximado del valor singular, basado en el extremo de la banda bidiagonal.
2. AplicaciÃ³n de rotaciones alternadas por la derecha e izquierda (tipo QR simÃ©trico implÃ­cito) para "empujar" el elemento fuera de banda hacia la esquina inferior.
3. EliminaciÃ³n (o reducciÃ³n por deflaciÃ³n) cuando algÃºn $f_i$ es suficientemente pequeÃ±o en magnitud.

Este proceso se repite hasta que toda la superdiagonal de $B$ se anula, y la matriz resultante se convierte en la matriz $\Sigma$ de la SVD. Las rotaciones aplicadas se acumulan en matrices ortogonales $U_2$ y $V_2$.


##### ğŸ”¹ Paso 3: ComposiciÃ³n final

Finalmente, la SVD completa de $A$ se reconstruye a partir de las transformaciones aplicadas:

$A = U \Sigma V^T, \quad \text{donde } U = U_1 U_2,\quad V = V_1 V_2$

En esta descomposiciÃ³n:
- la matriz $\Sigma$ es una matriz diagonal con los valores singulares ordenados,
- las matrices $U$ y $V$ son ortogonales, y
- el proceso es **estable**, ya que todas las operaciones se realizan con transformaciones ortogonales.

"""

# â•”â•â•¡ c0b961d8-3400-4d21-a6ba-3953f48accd8
md"
## ğŸ¤– Implementaciones
"

# â•”â•â•¡ 5584e9c6-ddff-4f96-a32e-fc0a9309617a
md"
### Funciones auxiliares
"

# â•”â•â•¡ 4b7d264c-0790-40a9-bf34-f7d1e31fcc41
"""
Analize si la matriz es ortogonal o no-
"""
function is_orthogonal(Q; atol=1e-12)
    n = size(Q, 2)
    return isapprox(Q' * Q, I(n), atol=atol)
end


# â•”â•â•¡ 6cd89edb-e55f-46bf-b6b1-39b2453cdf1e
"""
Reconstruye la matriz original A a partir de su descomposiciÃ³n SVD.
Recibe un objeto F retornado por la funciÃ³n svd(A).
Devuelve A â‰ˆ U * Î£ * Váµ€
"""
function reconstruct_from_svd(F)
    m, n = size(F.U, 1), size(F.V, 1)
    Î£ = zeros(m, n)
    for i in 1:length(F.S)
        Î£[i, i] = F.S[i]
    end
    return F.U * Î£ * F.V'
end

# â•”â•â•¡ ea4159af-a82d-40b2-ace2-c689aaeecd0d
"""
Valida una descomposiciÃ³n SVD comparando la matriz original A
con su reconstrucciÃ³n desde la tupla o estructura SVD `F`.

Imprime la norma del error â€–A - UÎ£Váµ€â€–â‚‚.
"""
function validate_svd(A::Matrix{Float64}, F)
    A_hat = reconstruct_from_svd(F)
    error = norm(A - A_hat)
    println("Error de reconstrucciÃ³n â€–A - UÎ£Váµ€â€–â‚‚ = ", error)
    return error
end


# â•”â•â•¡ 8b67358e-800f-4bf9-8869-90b29612e51e
struct SVDReconstruction
    U::Matrix{Float64}
    S::Vector{Float64}
    V::Matrix{Float64}
end


# â•”â•â•¡ beac433a-c1f4-4191-899f-6eb37d929889
example = randn(5, 3)

# â•”â•â•¡ aab73b0c-4d6e-467e-aaf8-93d8456508bc
md"
### SVD nativo de Julia
Utilizamos la funciÃ³n `LinearAlgebra.svd`
"

# â•”â•â•¡ bb27217f-4d64-4e47-946d-65a4590226ea
svd

# â•”â•â•¡ e2d4f475-165a-47dc-a4ab-1e9b1f97be3f
md"#### Ejemplo"

# â•”â•â•¡ f2d58441-03af-4efb-9ad5-f3628511d7fa
F1 = svd(example, full=true)

# â•”â•â•¡ c7b2ba31-3e8a-4c66-8583-d7817bf53e1b
reconstruct_from_svd(F1)

# â•”â•â•¡ d804ab81-03bb-4770-a508-d58dc204de2b
validate_svd(example, F1)

# â•”â•â•¡ b6b0df75-1ffa-44bb-9b74-518bb918e8ab
md"### MÃ©todo ingenuo"

# â•”â•â•¡ 5655e762-fc65-48da-a4d8-9bbf0cf5e3fc
"""
Calcula la SVD de A utilizando el enfoque clÃ¡sico basado en formar C = Aáµ€A.
Paso 1: Formar C = Aáµ€A
Paso 2: Calcular la descomposiciÃ³n espectral de C = VÎ›Váµ€ usando QR simÃ©trico
Paso 3: Calcular AV = QR para obtener U
Devuelve U, Î£, Váµ€
"""
function svd_via_ata(A::Matrix{Float64})
    m, n = size(A)

    # Step 1: Form the symmetric matrix C = Aáµ€A
    C = A' * A

    # Step 2: Compute eigen-decomposition of C = VÎ›Váµ€
    # This corresponds to applying the symmetric QR algorithm to C
    quadratic_eigenvalues, V = eigen(Symmetric(C))
    eigenvalues = sqrt.(clamp.(quadratic_eigenvalues, 0.0, Inf))

    # Step 3: Compute AV = QR to obtain U
    AV = A * V
    Q, _ = qr(AV)  # QR
    U = collect(Q) # Get full Q

    return SVDReconstruction(U, eigenvalues, V)
end

# â•”â•â•¡ 59f9f7e8-f355-40a3-94e0-5cb3c6dec15d
md"#### Ejemplo "

# â•”â•â•¡ 40a0849e-6ad5-4b70-b708-5cb1d92ed578
F2 = svd_via_ata(example)

# â•”â•â•¡ 6363a2cf-a7bf-475b-8f9c-0de2c5c66697
reconstruct_from_svd(F2)

# â•”â•â•¡ 08313203-f0ae-4603-be49-a85da9ffe178
validate_svd(example,F2)

# â•”â•â•¡ 247c0f32-0141-424f-9e8d-6dda19a521db
md"""
### MÃ©todo de Golubâ€“Kahan
#### Funciones auxiliares
"""

# â•”â•â•¡ 311a1fdd-e0cc-413a-81c5-262e29a1132b
md"
#### Paso de Golub-Kahan"

# â•”â•â•¡ d5e98c9e-92ee-454d-9de8-7c5f38e89c68
"""
Calcula el shift de Wilkinson (mu) a partir de los tres elementos finales de B bidiagonal.

Inputs:
- dm: elemento d_{n-1} (penÃºltimo de la diagonal)
- fm: elemento f_{n-1} (Ãºltimo de la superdiagonal)
- dn: elemento d_n (Ãºltimo de la diagonal)

Output:
- mu: shift de Wilkinson
"""
function wilkinson_shift(dm::Float64, fm::Float64, dn::Float64)
    tmm = dm^2 + fm^2
    tmn = fm * dn
    tnn = dn^2

    Î´ = (tmm - tnn) / 2
    denom = abs(Î´) + sqrt(Î´^2 + tmn^2)

    if denom == 0
        return tnn
    else
        return tnn - sign(Î´) * tmn^2 / denom
    end
end


# â•”â•â•¡ 7902449e-e1ca-4dd7-aef1-96d32e051f40
"""
Devuelve (c, s, r) tal que [c s; -s c] * [y; z] = [r; 0]
"""
function givens_rotation(y::Float64, z::Float64)
    if z == 0
        return (1.0, 0.0, y)
    elseif y == 0
        return (0.0, 1.0, z)
    else
        r = hypot(y, z)
        return (y / r, z / r, r)
    end
end


# â•”â•â•¡ adba5d98-0080-4d56-81ca-897d8a97eb39
"""
Aplica un paso QR bidiagonal de Golubâ€“Kahan a una matriz bidiagonal superior B âˆˆ â„^{nÃ—n}.

- B debe tener solo elementos en la diagonal y superdiagonal.
- La estructura bidiagonal se preserva.
- La transformaciÃ³n es ortogonal y mantiene aproximadamente los autovalores de Báµ—B.

Modifica B in-place.
"""
function golub_kahan_svd_step_matrix!(B::Matrix{Float64})
    n = size(B, 1)
    @assert size(B, 2) == n

    # Calcular el shift de Wilkinson
    d = diag(B)
    f = [B[i, i+1] for i in 1:n-1]
    Î¼ = wilkinson_shift(d[end-1], f[end], d[end])

    # Inicializar el primer vector para la rotaciÃ³n por la derecha
    y = d[1]^2 - Î¼
    z = d[1] * B[1, 2]

    for k in 1:n-1
        # -------- RotaciÃ³n por la derecha (columnas k, k+1) --------
        c, s, _ = givens_rotation(y, z)

        # Solo columnas k y k+1 de filas k y siguientes (preservar estructura)
        for i in k:n
            t1 = B[i, k]
            t2 = B[i, k+1]
            B[i, k]   =  c * t1 + s * t2
            B[i, k+1] = -s * t1 + c * t2
        end

        # -------- RotaciÃ³n por la izquierda (filas k, k+1) --------
        y = B[k, k]
        z = B[k+1, k]
        c, s, _ = givens_rotation(y, z)

        # Solo filas k y k+1 de columnas k y siguientes
        for j in k:n
            t1 = B[k, j]
            t2 = B[k+1, j]
            B[k, j]   =  c * t1 + s * t2
            B[k+1, j] = -s * t1 + c * t2
        end

        # Preparar vector (y, z) para la prÃ³xima rotaciÃ³n por la derecha
        if k < n - 1
            y = B[k, k+1]
            z = B[k, k+2]
        end
    end

    # Limpiar numÃ©ricamente la matriz fuera de la banda bidiagonal
    for i in 1:n
        for j in 1:n
            if j â‰  i && j â‰  i+1
                B[i, j] = 0.0
            end
        end
    end

    return B
end


# â•”â•â•¡ 7f39475d-a3c9-4c5c-8a55-aa2ba34d6289
md"##### ValidaciÃ³n"


# â•”â•â•¡ c2105a86-9dda-4ccb-a9df-cba3c10b6161
"""
Construye una matriz bidiagonal superior B âˆˆ â„^{nÃ—n} a partir de:

- d: diagonal de B, longitud n
- f: superdiagonal de B, longitud n - 1

Retorna: B :: Matrix{Float64}, una matriz nÃ—n con estructura bidiagonal superior.
"""
function build_bidiagonal(d, f)
    n = length(d)
    @assert length(f) == n - 1 "La superdiagonal f debe tener longitud n - 1"

    B = zeros(Float64, n, n)

    for i in 1:n
        B[i, i] = d[i]
        if i < n
            B[i, i+1] = f[i]
        end
    end

    return B
end


# â•”â•â•¡ 8ca30862-249a-444d-8a79-702ec8732935
"""
Compara `wilkinson_shift` con el verdadero autovalor de una matriz 2x2 para validar.
"""
function validate_shift(dm, fm, dn)
    T = [
        dm^2 + fm^2    fm * dn
        fm * dn        dn^2
    ]
    Î» = eigen(T).values
    Î¼_ref = Î»[argmin(abs.(Î» .- dn^2))]  # autovalor mÃ¡s cercano a t_nn
    Î¼_custom = wilkinson_shift(dm, fm, dn)
    
    println("Î¼ (eigen 2Ã—2)     = $Î¼_ref")
    println("Î¼ (Wilkinson calc)= $Î¼_custom")
    println("Error             = $(abs(Î¼_custom - Î¼_ref))")
end


# â•”â•â•¡ a1c28c45-10de-460c-909f-ab724f2afd45
"""
Valida un paso de Golubâ€“Kahan aplicado a una matriz bidiagonal B.

- step_func: funciÃ³n que modifica B in-place (como golub_kahan_svd_step_matrix!)
- B: matriz bidiagonal cuadrada (con solo diagonal y superdiagonal)

Opcional:
- verbose = true: imprime detalles
- atol: tolerancia para comparar autovalores

Retorna: true si todo pasa, false si falla alguna prueba.
"""
function validate_golub_kahan_step(step_func::Function, B::Matrix{Float64};
                                   atol=1e-10, verbose=true)
    n = size(B, 1)
    @assert size(B, 2) == n "B debe ser cuadrada"

    # --- Copiar datos originales ---
    B_before = copy(B)
    T_before = B_before' * B_before
    Î»_before = sort(eigvals(Symmetric(T_before)))

    # --- Aplicar paso QR bidiagonal ---
    step_func(B)

    # --- Verificar estructura bidiagonal ---
    is_bidiagonal = all(i == j || j == i+1 || B[i, j] == 0.0 for i in 1:n, j in 1:n)

    # --- Comparar autovalores ---
    T_after = B' * B
    Î»_after = sort(eigvals(Symmetric(T_after)))
    Î»_diff = norm(Î»_before - Î»_after, Inf)

    # --- Imprimir si se desea ---
    if verbose
        println("âœ” Estructura bidiagonal: ", is_bidiagonal)
        println("âœ” Autovalores antes:  ", round.(Î»_before, digits=8))
        println("âœ” Autovalores despuÃ©s:", round.(Î»_after, digits=8))
        println("Î”Î» âˆ-norm: ", Î»_diff)
    end

    return is_bidiagonal && Î»_diff â‰¤ atol
end


# â•”â•â•¡ 8ec72b94-d090-4c76-bde4-70787a67461a
validate_golub_kahan_step(
	golub_kahan_svd_step_matrix!, 
	build_bidiagonal(
		[1.0, 2.0, 3.0, 4.0], 
		[1.0, 1.0, 0.01]
	)
)

# â•”â•â•¡ e344fe0e-b939-4163-84ac-01c402895e38
md"#### DiagonalizaciÃ³n"

# â•”â•â•¡ b2928cde-9e9b-4d28-8a0a-45bae8e8f4ef
"""
Applies the full Golubâ€“Kahan SVD iteration (Algorithm 8.6.2) on a real upper bidiagonal matrix B.

This function repeatedly applies the Golubâ€“Kahan SVD step with Wilkinson shift to deflate
the superdiagonal of B until it becomes numerically zero (i.e., diagonalizes B).

The bidiagonal structure is preserved, and the function modifies B in-place.

Inputs:
- B::Matrix{Float64}: square upper bidiagonal matrix (with only diagonal and superdiagonal)
- Ïµ: relative tolerance for deflation (default: 100 Ã— eps(Float64))

Output:
- B is modified in-place to become diagonal (approximate singular values on the diagonal)
"""
function golub_kahan_svd_matrix!(B::Matrix{Float64}; Ïµ = 100 * eps(Float64))
    n = size(B, 1)
    @assert size(B, 2) == n "B must be square"
    
    while true
        # Step 1: deflation â€” set small superdiagonal entries to zero
        for i in 1:n-1
            d1 = abs(B[i, i])
            d2 = abs(B[i+1, i+1])
            tol = Ïµ * (d1 + d2)
            if abs(B[i, i+1]) â‰¤ tol
                B[i, i+1] = 0.0
            end
        end

        # Step 2: find the largest q such that B[q-1, q] â‰  0
        q = n
        while q > 1 && B[q-1, q] == 0.0
            q -= 1
        end

        if q == 1
            break  # Fully diagonalized
        end

        # Step 3: find the smallest p such that B[p-1, p] == 0
        p = q - 1
        while p > 1 && B[p-1, p] â‰  0.0
            p -= 1
        end

        # Step 4: handle zeros on the diagonal
        zero_on_diag = false
        maxd = maximum(abs.(diag(B)))
        for i in p:q
            if abs(B[i, i]) â‰¤ Ïµ * maxd
                zero_on_diag = true
                break
            end
        end

        if zero_on_diag
            for i in p:q-1
                if abs(B[i, i]) â‰¤ Ïµ * maxd
                    B[i, i+1] = 0.0
                end
            end
        elseif q - p + 1 â‰¥ 2
            # Step 5: apply one Golubâ€“Kahan step to the active block
            Bblock = B[p:q, p:q]
            golub_kahan_svd_step_matrix!(Bblock)
            B[p:q, p:q] .= Bblock
        end
    end

    return B
end


# â•”â•â•¡ 502c0650-1925-4174-8c8e-dd963728c7b2
md"##### ValidaciÃ³n"

# â•”â•â•¡ b4276865-6a07-484a-9290-7d557af8ac88
"""
Verifica la correcciÃ³n de golub_kahan_svd_matrix! sobre una matriz bidiagonal B.

- B: matriz bidiagonal cuadrada (modificada in-place)
- atol: tolerancia absoluta sobre errores espectrales y fuera de la diagonal
- verbose: si true, imprime diferencias y estructura

Retorna: true si todo estÃ¡ correcto, false si falla alguna validaciÃ³n.
"""
function validate_golub_kahan_svd_matrix(B::Matrix{Float64}; atol=1e-10, verbose=true)
    n = size(B, 1)
    @assert size(B, 2) == n "B debe ser cuadrada"

    # Copia para comparar
    B0 = copy(B)
    Î»0 = sort(eigvals(Symmetric(B0' * B0)))

    # Ejecutar algoritmo
    golub_kahan_svd_matrix!(B)

    # VerificaciÃ³n 1: la matriz resultante debe ser diagonal (bidiagonal con superdiagonal â‰ˆ 0)
    is_diagonal = all(abs(B[i, j]) â‰¤ atol for i in 1:n, j in 1:n if i â‰  j)

    # VerificaciÃ³n 2: los autovalores de Báµ—B deben conservarse
    Î»f = sort(eigvals(Symmetric(B' * B)))
    Î»_diff = norm(Î»0 - Î»f, Inf)

    # VerificaciÃ³n 3: valores singulares ordenados (opcional)
    Ïƒ = sort(abs.(diag(B)), rev=true)

    if verbose
        println("âœ” Diagonal final: ", is_diagonal)
        println("âœ” Autovalores iniciales: ", round.(Î»0, digits=8))
        println("âœ” Autovalores finales:   ", round.(Î»f, digits=8))
        println("Î”Î» âˆ-norm: ", Î»_diff)
        println("âœ” Valores singulares:    ", round.(Ïƒ, digits=8))
    end

    return is_diagonal && Î»_diff â‰¤ atol
end


# â•”â•â•¡ c756f929-8da9-41f6-aa58-6247d2a57acb
validate_golub_kahan_svd_matrix(
	build_bidiagonal(
		[1.0, 2.0, 3.0, 4.0],
		[1.0, 1.0, 0.01]
	)
)

# â•”â•â•¡ 3069c786-0823-42a0-92c0-4df61174e5d1
md"
Podemos ver que los autovalores parecen conservarse en las validaciones de `golub_kahan_svd_step_matrix` y `golub_kahan_svd_matrix`. Sin embargo la norma del error es demasiado grande. Esto nos dice que no es un problema de la lÃ³gica del algoritmo, sino de su implementaciÃ³n.
Por esto, creemos otra implementaciÃ³n que utilice la matriz bidiagonal de manera implÃ­cita.
"

# â•”â•â•¡ 04eb9c27-8a4f-462e-930a-4f643d424769
md"#### Algoritmo de Golub Kahan"

# â•”â•â•¡ 4e69684e-b6bb-439a-a8c7-3a65ebb36f25
"""
Reduce la matriz A a forma bidiagonal utilizando reflexiones de Householder.
Devuelve la matriz bidiagonal B, y las matrices ortogonales U y V tal que A â‰ˆ U * B * Váµ€.
"""
function bidiagonalize_householder(A::Matrix{Float64})
    m, n = size(A)
    B = copy(A)
    U = Matrix{Float64}(I, m, m)
    V = Matrix{Float64}(I, n, n)

    for i in 1:min(m, n)
        # ReflexiÃ³n de Householder desde la izquierda (columnas)
        x = B[i:end, i]
        v = copy(x)
        v[1] += sign(x[1]) * norm(x)
        v = v / norm(v)
        B[i:end, i:end] -= 2 * v * (v' * B[i:end, i:end])
        U[:, i:end] -= 2 * (U[:, i:end] * v) * v'

        if i < n
            # ReflexiÃ³n de Householder desde la derecha (filas)
            x = B[i, i+1:end]'
            v = copy(x)
            v[1] += sign(x[1]) * norm(x)
            v = v / norm(v)
            B[i:end, i+1:end] -= 2 * (B[i:end, i+1:end] * v') * v
            V[:, i+1:end] -= 2 * (V[:, i+1:end] * v') * v
        end
    end

    return B, U, V
end


# â•”â•â•¡ cfa62a92-828e-4510-81ae-985e84e2250e
"""
Fuerza a cero los elementos de la matriz B que estÃ¡n fuera de la banda bidiagonal,
si su magnitud es menor que un umbral dado (por defecto 1e-14).
Esto es Ãºtil para limpiar errores numÃ©ricos tras la bidiagonalizaciÃ³n.

Modifica B in-place.
"""
function force_bidiagonal!(B::Matrix{Float64}; atol=1e-14)
    m, n = size(B)
    for i in 1:m
        for j in 1:n
            if j != i && j != i+1 && abs(B[i,j]) < atol
                B[i,j] = 0.0
            end
        end
    end
end


# â•”â•â•¡ c1a1f0f7-39a9-4597-9c1e-3358b0ee232d
begin
	Y = randn(5, 3)
	B, U, V = bidiagonalize_householder(Y)
	A_hat = U * B * V'
	println("Error de reconstrucciÃ³n: ", norm(Y - A_hat))
	
end

# â•”â•â•¡ d8888165-0100-4c40-8bd1-0182f91e3565
begin
	
	function is_bidiagonal(B; atol=1e-12)
	    m, n = size(B)
	    for i in 1:m
	        for j in 1:n
	            if (j != i && j != i+1) && abs(B[i,j]) > atol
	                return false
	            end
	        end
	    end
	    return true
	end
	
	@show is_bidiagonal(B)
end

# â•”â•â•¡ 65aa59c8-586f-4850-875c-7a19ed968882
"""
Calcula la SVD de una matriz A âˆˆ â„^{mÃ—n} utilizando el algoritmo de Golub-Kahan.
Paso 1: BidiagonalizaciÃ³n de A usando reflexiones de Householder.
Paso 2: DiagonalizaciÃ³n iterativa de la matriz bidiagonal mediante rotaciones de Givens.
Devuelve U, Î£, Váµ€
"""
function svd_golub_kahan(A::Matrix{Float64}; tol=1e-12, maxiter=1000)
    m, n = size(A)
    B, U, V = bidiagonalize_householder(A)
	force_bidiagonal!(B)
	B = B[1:n, 1:n]
    golub_kahan_svd_matrix!(B)
	display(B)
    Î£ = zeros(m, n)
    for i in 1:min(m,n)
        Î£[i,i] = abs(B[i,i])
    end

    return SVDReconstruction(U, diag(Î£), V')
end


# â•”â•â•¡ 6c502074-cfa6-4d7d-8754-b4114743aaeb
md"#### Ejemplo y validaciÃ³n"

# â•”â•â•¡ 537968ea-5d8c-4adc-9f36-d229e21d4085
begin
	F3 = svd_golub_kahan(example)
	validate_svd(example,F3)
end

# â•”â•â•¡ 4f81f155-f5c7-42f2-8e10-af8ae8ad1dae
A_reconstructed = reconstruct_from_svd(F3)

# â•”â•â•¡ ab104798-39bf-44cb-ad07-9d5592524730
md" ### Funciones auxiliares extra"

# â•”â•â•¡ d79631a6-4494-49bd-a9e5-8b100de0272d
"""
Aplica rotaciÃ³n de Givens por la derecha sobre d[k] y f[k]
"""
function apply_right_rotation!(d, f, k::Int, c::Float64, s::Float64)
    d_k  = d[k]
    f_k  = f[k]
    d[k] =  c * d_k + s * f_k
    f[k] = -s * d_k + c * f_k
end


# â•”â•â•¡ 2edc23a7-b981-4416-8516-54084054bd74
"""
Aplica rotaciÃ³n de Givens por la izquierda sobre d[k] y d[k+1]
"""
function apply_left_rotation!(d, k::Int, c::Float64, s::Float64)
    d_k  = d[k]
    d_k1 = d[k+1]
    d[k]   =  c * d_k + s * d_k1
    d[k+1] = -s * d_k + c * d_k1
end


# â•”â•â•¡ a48dea5f-3e17-45d2-9a07-7eb0228ca516
"""
Diagonaliza la matriz bidiagonal B utilizando rotaciones de Givens
y acumula las transformaciones en U y V.
Modifica B, U y V in-place.
"""
function diagonalize_bidiagonal!(B::Matrix{Float64}, U::Matrix{Float64}, V::Matrix{Float64};
                                  tol=1e-12, maxiter=1000)

    m, n = size(B)
    for iter = 1:maxiter
        converged = true

        for i in 1:n-1
            # Verifica si el elemento fuera de la diagonal es significativo
            if abs(B[i, i+1]) > tol * (abs(B[i,i]) + abs(B[i+1,i+1]))
                converged = false

                # Paso 1: rotaciÃ³n a la derecha (columna i e i+1 de B y V)
                x = B[i,i]^2 - B[i+1,i+1]^2
                y = B[i,i] * B[i,i+1]
                c, s = givens_rotation(x, y)

                apply_right_rotation!(B, i, i+1, c, s)
                apply_right_rotation!(V, i, i+1, c, s)

                # Paso 2: rotaciÃ³n a la izquierda (fila i e i+1 de B y U)
                c, s = givens_rotation(B[i,i], B[i+1,i])
                apply_left_rotation!(B, i, i+1, c, s)
                apply_right_rotation!(U, i, i+1, c, s)
            end
        end

        if converged
            break
        end
    end
end


# â•”â•â•¡ a0b20c8f-64dd-4966-87c3-ba4156ebdbf2
md"##### Ejemplo"

# â•”â•â•¡ 78ad67b1-5ead-4d3e-b5bb-062907f524f5
md"---"

# â•”â•â•¡ 277c10ee-bd03-4efe-b54b-0d835a8781a0
md"### Old: ğŸ‘¾ MÃ©todo implÃ­cito"

# â•”â•â•¡ 9a929fc1-a2b2-474a-9deb-4d8a6bc6d7d1
"""
Computa los valores singulares de una matriz A âˆˆ â„^{mÃ—n} (con m â‰¥ n)
usando la descomposiciÃ³n bidiagonal seguida de la iteraciÃ³n QR implÃ­cita
(Golubâ€“Kahan, Algoritmo 8.6.2 de Golub y Van Loan).

No acumula U ni V explÃ­citamente (solo valores singulares).
"""
function svd_golub_kahan_values(A::Matrix{Float64}; Ïµ = 100 * eps(Float64))
    m, n = size(A)
    @assert m â‰¥ n "Se requiere m â‰¥ n"

    # Paso 1: ReducciÃ³n bidiagonal A = Uâ‚ * B * Vâ‚áµ—
    B_full = copy(A)
    U1 = Matrix{Float64}(I, m, m)
    V1 = Matrix{Float64}(I, n, n)
    LinearAlgebra.bidiagonalize!(B_full, U1, V1)

    # Extraer la bidiagonal B
    d = diag(B_full[1:n, 1:n])           # diagonal
    f = [B_full[i, i+1] for i in 1:n-1]  # superdiagonal

    # Paso 2: IteraciÃ³n QR implÃ­cita sobre (d, f)
    function is_converged(f, d)
        all(abs(f[i]) â‰¤ Ïµ * (abs(d[i]) + abs(d[i+1])) for i in 1:length(f))
    end

    while !is_converged(f, d)
        golub_kahan_svd_step!(d, f)
    end

    # Retornar valores singulares ordenados
    return sort(abs.(d); rev=true)
end


# â•”â•â•¡ cb27deb4-cefa-4d34-b29f-be8fd219035d
md"""begin
	# Matriz de prueba
	A = randn(6, 4)
	
	# SVD por Golubâ€“Kahan implÃ­cito (solo valores singulares)
	Ïƒ = svd_golub_kahan_values(A)
	
	# SVD de referencia usando la funciÃ³n estÃ¡ndar de Julia
	Ïƒ_ref = svd(A).S
	
	# Mostrar resultados
	println("Ïƒ (GK implÃ­cito) = ", round.(Ïƒ, digits=6))
	println("Ïƒ (referencia)   = ", round.(Ïƒ_ref, digits=6))
	println("Error absoluto    = ", round.(maximum(abs.(Ïƒ .- Ïƒ_ref)), digits=6))
	
end"""

# â•”â•â•¡ 00ca8f64-6937-45ee-8970-d1c2bf49fd59
md"
## To Do:
- [X] Have a working Golub
* - [ ] Full algorithm (From initial Householder)
* - [x] Make a verification function
* - [ ] How to get the SVD from the result?
- [ ] Add or transform into a `Bidiagonal` version (does it count as implicit?)
- [X] Add other implementation (either classical or Jacobi)
     -> Comparar con versiÃ³n INGENUA, no clÃ¡sica.
"

# â•”â•â•¡ 00000000-0000-0000-0000-000000000001
PLUTO_PROJECT_TOML_CONTENTS = """
[deps]
LinearAlgebra = "37e2e46d-f89d-539d-b4ee-838fcccc9c8e"
"""

# â•”â•â•¡ 00000000-0000-0000-0000-000000000002
PLUTO_MANIFEST_TOML_CONTENTS = """
# This file is machine-generated - editing it directly is not advised

julia_version = "1.11.1"
manifest_format = "2.0"
project_hash = "ac1187e548c6ab173ac57d4e72da1620216bce54"

[[deps.Artifacts]]
uuid = "56f22d72-fd6d-98f1-02f0-08ddc0907c33"
version = "1.11.0"

[[deps.CompilerSupportLibraries_jll]]
deps = ["Artifacts", "Libdl"]
uuid = "e66e0078-7015-5450-92f7-15fbd957f2ae"
version = "1.1.1+0"

[[deps.Libdl]]
uuid = "8f399da3-3557-5675-b5ff-fb832c97cbdb"
version = "1.11.0"

[[deps.LinearAlgebra]]
deps = ["Libdl", "OpenBLAS_jll", "libblastrampoline_jll"]
uuid = "37e2e46d-f89d-539d-b4ee-838fcccc9c8e"
version = "1.11.0"

[[deps.OpenBLAS_jll]]
deps = ["Artifacts", "CompilerSupportLibraries_jll", "Libdl"]
uuid = "4536629a-c528-5b80-bd46-f80d51c5b363"
version = "0.3.27+1"

[[deps.libblastrampoline_jll]]
deps = ["Artifacts", "Libdl"]
uuid = "8e850b90-86db-534c-a0d3-1478176c7d93"
version = "5.11.0+0"
"""

# â•”â•â•¡ Cell order:
# â•Ÿâ”€a58e9c22-51a1-11f0-0fc0-914efb421b18
# â• â•701241c2-322f-45ca-b17d-437cf32a7ff3
# â•Ÿâ”€11b2ebb7-626e-49c1-a294-c9b834c73bdb
# â•Ÿâ”€6b68d0ac-8118-44aa-940e-5a807217e562
# â•Ÿâ”€56ef11c7-1b71-45f7-b286-38a932ac3dc4
# â•Ÿâ”€dbb9e53d-bb68-4220-a32d-6c3ce32e274a
# â•Ÿâ”€85c6df45-20ef-4db2-8703-ddf76166832e
# â•Ÿâ”€74470dd1-eb43-4039-9d93-6bdf32768466
# â•Ÿâ”€c0b961d8-3400-4d21-a6ba-3953f48accd8
# â•Ÿâ”€5584e9c6-ddff-4f96-a32e-fc0a9309617a
# â•Ÿâ”€4b7d264c-0790-40a9-bf34-f7d1e31fcc41
# â•Ÿâ”€6cd89edb-e55f-46bf-b6b1-39b2453cdf1e
# â•Ÿâ”€ea4159af-a82d-40b2-ace2-c689aaeecd0d
# â• â•8b67358e-800f-4bf9-8869-90b29612e51e
# â• â•beac433a-c1f4-4191-899f-6eb37d929889
# â•Ÿâ”€aab73b0c-4d6e-467e-aaf8-93d8456508bc
# â•Ÿâ”€bb27217f-4d64-4e47-946d-65a4590226ea
# â•Ÿâ”€e2d4f475-165a-47dc-a4ab-1e9b1f97be3f
# â•Ÿâ”€f2d58441-03af-4efb-9ad5-f3628511d7fa
# â•Ÿâ”€c7b2ba31-3e8a-4c66-8583-d7817bf53e1b
# â•Ÿâ”€d804ab81-03bb-4770-a508-d58dc204de2b
# â•Ÿâ”€b6b0df75-1ffa-44bb-9b74-518bb918e8ab
# â•Ÿâ”€5655e762-fc65-48da-a4d8-9bbf0cf5e3fc
# â•Ÿâ”€59f9f7e8-f355-40a3-94e0-5cb3c6dec15d
# â•Ÿâ”€40a0849e-6ad5-4b70-b708-5cb1d92ed578
# â•Ÿâ”€6363a2cf-a7bf-475b-8f9c-0de2c5c66697
# â•Ÿâ”€08313203-f0ae-4603-be49-a85da9ffe178
# â•Ÿâ”€247c0f32-0141-424f-9e8d-6dda19a521db
# â•Ÿâ”€d5e98c9e-92ee-454d-9de8-7c5f38e89c68
# â•Ÿâ”€7902449e-e1ca-4dd7-aef1-96d32e051f40
# â•Ÿâ”€c2105a86-9dda-4ccb-a9df-cba3c10b6161
# â•Ÿâ”€8ca30862-249a-444d-8a79-702ec8732935
# â•Ÿâ”€311a1fdd-e0cc-413a-81c5-262e29a1132b
# â• â•adba5d98-0080-4d56-81ca-897d8a97eb39
# â•Ÿâ”€7f39475d-a3c9-4c5c-8a55-aa2ba34d6289
# â•Ÿâ”€a1c28c45-10de-460c-909f-ab724f2afd45
# â• â•8ec72b94-d090-4c76-bde4-70787a67461a
# â•Ÿâ”€e344fe0e-b939-4163-84ac-01c402895e38
# â•Ÿâ”€b2928cde-9e9b-4d28-8a0a-45bae8e8f4ef
# â•Ÿâ”€502c0650-1925-4174-8c8e-dd963728c7b2
# â•Ÿâ”€b4276865-6a07-484a-9290-7d557af8ac88
# â• â•c756f929-8da9-41f6-aa58-6247d2a57acb
# â•Ÿâ”€3069c786-0823-42a0-92c0-4df61174e5d1
# â•Ÿâ”€04eb9c27-8a4f-462e-930a-4f643d424769
# â•Ÿâ”€4e69684e-b6bb-439a-a8c7-3a65ebb36f25
# â•Ÿâ”€cfa62a92-828e-4510-81ae-985e84e2250e
# â•Ÿâ”€c1a1f0f7-39a9-4597-9c1e-3358b0ee232d
# â•Ÿâ”€d8888165-0100-4c40-8bd1-0182f91e3565
# â•Ÿâ”€a48dea5f-3e17-45d2-9a07-7eb0228ca516
# â•Ÿâ”€65aa59c8-586f-4850-875c-7a19ed968882
# â•Ÿâ”€6c502074-cfa6-4d7d-8754-b4114743aaeb
# â• â•4f81f155-f5c7-42f2-8e10-af8ae8ad1dae
# â• â•537968ea-5d8c-4adc-9f36-d229e21d4085
# â•Ÿâ”€ab104798-39bf-44cb-ad07-9d5592524730
# â•Ÿâ”€d79631a6-4494-49bd-a9e5-8b100de0272d
# â•Ÿâ”€2edc23a7-b981-4416-8516-54084054bd74
# â•Ÿâ”€a0b20c8f-64dd-4966-87c3-ba4156ebdbf2
# â•Ÿâ”€78ad67b1-5ead-4d3e-b5bb-062907f524f5
# â•Ÿâ”€277c10ee-bd03-4efe-b54b-0d835a8781a0
# â•Ÿâ”€9a929fc1-a2b2-474a-9deb-4d8a6bc6d7d1
# â•Ÿâ”€cb27deb4-cefa-4d34-b29f-be8fd219035d
# â•Ÿâ”€00ca8f64-6937-45ee-8970-d1c2bf49fd59
# â•Ÿâ”€00000000-0000-0000-0000-000000000001
# â•Ÿâ”€00000000-0000-0000-0000-000000000002

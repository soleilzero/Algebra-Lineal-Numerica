### A Pluto.jl notebook ###
# v0.20.3

using Markdown
using InteractiveUtils

# ‚ïî‚ïê‚ï° 701241c2-322f-45ca-b17d-437cf32a7ff3
using LinearAlgebra

# ‚ïî‚ïê‚ï° a58e9c22-51a1-11f0-0fc0-914efb421b18
md"""
# C√°lculo Num√©rico de la SVD: Algoritmo de Golub‚ÄìKahan

## √çndice
1. Objetivos
1. Introducci√≥n
1. Fundamentos te√≥ricos
3. Algoritmos
"""

# ‚ïî‚ïê‚ï° 11b2ebb7-626e-49c1-a294-c9b834c73bdb
md"
## Objetivos

Explicar y analizar detalladamente el algoritmo num√©rico para calcular la descomposici√≥n en valores singulares (SVD), con √©nfasis en el enfoque de Golub‚ÄìKahan basado en la reducci√≥n bidiagonal y la iteraci√≥n QR impl√≠cita.

* Exponer las conexiones te√≥ricas entre la SVD y los problemas de autovalores sim√©tricos,
* analizar el comportamiento num√©rico del algoritmo cl√°sico frente a m√©todos mal condicionados,
* implementar y visualizar los pasos clave del algoritmo de Golub‚ÄìKahan,
* discutir la eficiencia computacional y estrategias pr√°cticas.

En otro trabajo se puede aplicar la SVD computada num√©ricamente a un problema pr√°ctico.

## Introducci√≥n 

La descomposici√≥n en valores singulares (SVD) es una de las herramientas m√°s poderosas y vers√°tiles del √°lgebra lineal num√©rica.
No solo existe para cualquier matriz y proporciona informaci√≥n estructural sobre ella ‚Äîcomo su rango, condici√≥n y modos principales de acci√≥n‚Äî, sino que tambi√©n constituye la base de aplicaciones fundamentales en an√°lisis de datos, compresi√≥n, m√©todos de m√≠nimos cuadrados, y problemas inversos.

Desde el punto de vista computacional, calcular la SVD de una matriz general $\in \mathbb{R}^{m \times n}$ de forma precisa y eficiente requiere mucho m√°s que aplicar definiciones algebraicas. De hecho, formar matrices como $A^T A$ puede llevar a errores num√©ricos significativos. Para abordar este desaf√≠o, Golub y Kahan propusieron en 1965 un algoritmo robusto y eficiente basado en dos pasos clave:

1. **Reducci√≥n bidiagonal de $A$** mediante transformaciones de Householder.
2. **Diagonalizaci√≥n de la matriz bidiagonal** resultante usando una iteraci√≥n QR adaptada, que opera de forma impl√≠cita sobre $B^T B$, sin construirla expl√≠citamente.

Este notebook est√° dedicado al estudio detallado de este algoritmo. Nuestro objetivo no es solo entender c√≥mo se implementa, sino por qu√© funciona, c√≥mo se conecta con los problemas sim√©tricos de autovalores, y qu√© garant√≠as num√©ricas ofrece.

A lo largo de este recorrido, desarrollaremos teor√≠a, visualizaremos ejemplos peque√±os y construiremos bloques de c√≥digo que ilustran cada etapa del proceso. Este an√°lisis est√° inspirado en la secci√≥n 8.6 del libro *Matrix Computations*, de Golub y Van Loan, una referencia cl√°sica en el √°rea.

> **Requisitos previos**: se asume familiaridad con transformaciones ortogonales (Householder, Givens), descomposici√≥n QR, y problemas de autovalores sim√©tricos.

---
"

# ‚ïî‚ïê‚ï° 6b68d0ac-8118-44aa-940e-5a807217e562
md"
## Fundamentos te√≥ricos de la SVD
Definici√≥n y existencia

Propiedades b√°sicas

SVD y matrices sim√©tricas asociadas ?

Matriz aumentada sim√©trica

Implicaciones algor√≠tmicas

### üü¢ Definici√≥n y existencia de la SVD

Sea $A \in \mathbb{R}^{m \times n}$. La **descomposici√≥n en valores singulares (SVD)** de $A$ es una factorizaci√≥n de la forma:

$A = U \Sigma V^T,$

donde
- las matrices $U \in \mathbb{R}^{m \times m}$ y $V \in \mathbb{R}^{n \times n}$ son ortogonales,
- la matriz $\Sigma \in \mathbb{R}^{m \times n}$ es diagonal rectangular con entradas no negativas en la diagonal:
  
$\Sigma = \begin{bmatrix}
\sigma_1 & & & \\
& & \ddots & \\
& & & \sigma_r \\
& & & & 0 \\
\end{bmatrix}, 
\quad \text{con } \sigma_1 \geq \sigma_2 \geq \cdots \geq \sigma_r > 0,$

y $r = \operatorname{rank}(A)$.

Las cantidades $\sigma_i$ se llaman **valores singulares** de $A$, y son √∫nicos. Los vectores columna de $U$ y $V$ se llaman **vectores singulares izquierdos** y **derechos**, respectivamente.

#### ‚ùó Teorema de existencia

**Toda** matriz real \( A \in \mathbb{R}^{m \times n} \), sea cuadrada, rectangular, singular o no, **admite una descomposici√≥n SVD** como la descrita arriba.

Esto contrasta con la factorizaci√≥n espectral, que solo existe para matrices sim√©tricas.

#### üß† Intuici√≥n geom√©trica

La SVD describe la acci√≥n de la matriz $A$ como una transformaci√≥n que:

1. **Rota** el espacio fuente (a trav√©s de $V^T$),
2. **Escala** en direcciones ortogonales (a trav√©s de $\Sigma$),
3. **Rota** el espacio imagen (a trav√©s de $U$).

En otras palabras, toda matriz real lineal puede descomponerse como una secuencia de rotaciones/reflexiones y escalamientos. Esta intuici√≥n es presentada de manera gr√°fica por Visual Kernel en el Cap√≠tulo 1 Visualize Different Matrices de su colecci√≥n SEE Matrix.


"

# ‚ïî‚ïê‚ï° 56ef11c7-1b71-45f7-b286-38a932ac3dc4
md"""
### üü¢ Propiedades b√°sicas de la SVD

Dada la descomposici√≥n $A = U \Sigma V^T$ de una matriz $A \in \mathbb{R}^{m \times n}$, se cumplen las siguientes propiedades fundamentales:

#### üîπ Ortogonalidad de los vectores singulares

- Las **columnas de $V$** (vectores singulares derechos) son autovectores de $A^T A$ y forman una base ortonormal de $\mathbb{R}^m$.
- Las **columnas de $U$** (vectores singulares izquierdos) son autovectores de $A A^T$ y forman una base ortonormal de $\mathbb{R}^n$.


#### üîπ Interpretaci√≥n de los valores singulares

- Los **autovalores** de $A^T A$ y $A A^T$ son exactamente $\sigma_i^2$.
- Los valores singulares $\sigma_i$ son los **autovalores positivos** de $A^T A$ o $A A^T$:
  $A^T A = V \Sigma^2 V^T, \quad A A^T = U \Sigma^2 U^T$
- Siempre se ordenan de forma no creciente:
  $\sigma_1 \geq \sigma_2 \geq \cdots \geq \sigma_r > 0$
- Se cumple que $\text{rank}(A) = r = \# \{ \sigma_i > 0 \}$.

#### üîπ Normas y condici√≥n

- Norma 2:
  $\| A \|_2 = \sigma_1$
- Norma de Frobenius:
  $\| A \|_F = \left( \sum_{i=1}^r \sigma_i^2 \right)^{1/2}$
- N√∫mero de condici√≥n (si $A$ es cuadrada y de rango completo):
  $\kappa_2(A) = \frac{\sigma_1}{\sigma_r}$

#### üîπ Descomposici√≥n como suma de rangos 1

La descomposici√≥n SVD permite representar cualquier matriz $A \in \mathbb{R}^{m \times n}$ como una **suma de matrices de rango 1**:

$A = \sum_{i=1}^r \sigma_i u_i v_i^T,$

donde $r = \operatorname{rank}(A)$, $u_i$ y $v_i$ son los vectores singulares izquierdo y derecho correspondientes al valor singular $\sigma_i$, cada t√©rmino $\sigma_i u_i v_i^T$ es una matriz de **rango 1**.

Esta forma revela que la SVD descompone $A$ como la suma de **modos b√°sicos** ordenados por importancia (es decir, energ√≠a o norma).

##### üî∏ Aproximaci√≥n de rango bajo √≥ptima

Una de las propiedades m√°s poderosas de la SVD es que permite construir la **mejor aproximaci√≥n de rango $k$** a $A$ en sentido de m√≠nima distancia, tanto en norma 2 como en norma de Frobenius.

Para cualquier $k < r$, definimos:

$A_k = \sum_{i=1}^k \sigma_i u_i v_i^T,$

entonces se cumple $\| A - A_k \|_2 = \sigma_{k+1}$ y $\| A - A_k \|_F^2 = \sum_{i = k+1}^r \sigma_i^2$.

Este resultado se conoce como el **teorema de Eckart‚ÄìYoung**, y afirma que $A_k$ es la mejor aproximaci√≥n de $A$ por una matriz de rango $k$, en el sentido de ser la m√°s cercana seg√∫n dichas normas.


##### üìå Consecuencias pr√°cticas

- Los primeros t√©rminos de la SVD capturan la **estructura principal** de $A$.
- Los t√©rminos restantes pueden considerarse **ruido o detalles finos**.
- Este principio es la base de muchas t√©cnicas de **compresi√≥n**, **reducci√≥n de dimensionalidad** y **filtrado**.

Ejemplos t√≠picos incluyen:
- Representar im√°genes usando solo los primeros 10 valores singulares.
- Aproximar grandes matrices de datos con bajo rango efectivo.

"""

# ‚ïî‚ïê‚ï° dbb9e53d-bb68-4220-a32d-6c3ce32e274a
md"""
## Algoritmo de c√°lculo de la SVD

* **Opci√≥n 1**: $A^T A$
* * Definici√≥n
* * Por qu√© no se usa
* **Opci√≥n 2**: Desde el punto de vista num√©rico, **¬øc√≥mo se calcula esta descomposici√≥n sin formar $A^T A$?**
* * Intro
* * Fundamentos te√≥ricos
* * M√©todo de Golub‚ÄìKahan

## Comparaci√≥n / An√°lisis de los algoritmos
En la secci√≥n anterior vimos que la SVD de una matriz $A \in \mathbb{R}^{m \times n}$ (con $m \geq n$) tiene la forma:

$A = U \Sigma V^T,$

donde $U$ y $V$ son ortogonales, y $\Sigma$ es una matriz diagonal rectangular con entradas no negativas.

"""

# ‚ïî‚ïê‚ï° 85c6df45-20ef-4db2-8703-ddf76166832e
md"""
## Algoritmos de c√°lculo de la SVD

En esta secci√≥n abordamos el problema de c√≥mo calcular num√©ricamente la descomposici√≥n en valores singulares de una matriz $A \in \mathbb{R}^{m \times n}$. Aunque su existencia est√° garantizada te√≥ricamente, el c√°lculo efectivo de las matrices $U$, $\Sigma$ y $V$ requiere algoritmos cuidadosamente dise√±ados para asegurar estabilidad y eficiencia, especialmente cuando $A$ est√° mal condicionada o es de gran tama√±o.

Comenzamos con el algoritmo cl√°sico, que se basa en la relaci√≥n $A^T A = V \Sigma^2 V^T$ y permite obtener los valores y vectores singulares a partir de la descomposici√≥n espectral. Este m√©todo es √∫til para fines pedag√≥gicos, pero es num√©ricamente inadecuado debido a su sensibilidad a errores de redondeo.

Luego presentaremos el m√©todo de Golub‚ÄìKahan, que constituye la base de las implementaciones modernas de la SVD. Este enfoque evita formar $A^T A$ y combina una reducci√≥n bidiagonal mediante transformaciones ortogonales con una versi√≥n adaptada del algoritmo QR para matrices sim√©tricas. Analizaremos este m√©todo en tres partes: una introducci√≥n conceptual, los fundamentos te√≥ricos que lo justifican, y una descripci√≥n detallada del algoritmo.

Por √∫ltimo, exploraremos otras variantes relevantes como el m√©todo de Jacobi, los algoritmos divide-and-conquer, y algunas estrategias paralelas. Estas alternativas ofrecen ventajas particulares en t√©rminos de precisi√≥n o rendimiento, y permiten comparar diferentes enfoques bajo distintas condiciones computacionales.


### Algoritmo cl√°sico

#### üîπ Definici√≥n

Dada una matriz $A \in \mathbb{R}^{m \times n}$, el producto $A^T A$ es una matriz sim√©trica y semidefinida positiva de tama√±o $n \times n$. Sus autovalores son no negativos, y sus autovectores son precisamente los vectores singulares derechos de $A$.

Adem√°s, se cumple:

$A^T A = V \Sigma^2 V^T,$

lo que sugiere que una forma de obtener los valores singulares ser√≠a:

1. Formar $C = A^T A$,
2. Calcular sus autovalores $\lambda_i$,
3. Obtener $\sigma_i = \sqrt{\lambda_i}$,
4. Recuperar $U$ a partir de $AV = U \Sigma$.

#### üî∏ ¬øPor qu√© no se usa este enfoque?

Aunque conceptualmente sencilla, esta estrategia es **num√©ricamente inestable**:

- **P√©rdida de precisi√≥n:** el c√°lculo de $A^T A$ **cuadra la condici√≥n** de $A$:
  $\kappa_2(A^T A) = \kappa_2(A)^2,$
  lo que magnifica errores cuando $A$ es mal condicionada.

- **Cancelaciones destructivas:** en aritm√©tica de punto flotante, calcular $A^T A$ puede eliminar informaci√≥n valiosa contenida en $A$.

- **No preserva la estructura original:** operaciones como la bidiagonalizaci√≥n s√≠ preservan mejor las propiedades num√©ricas de $A$.

Por estas razones, los algoritmos modernos evitan formar expl√≠citamente $A^T A$, y utilizan en cambio m√©todos m√°s estables, como el de **Golub‚ÄìKahan**.


"""

# ‚ïî‚ïê‚ï° 74470dd1-eb43-4039-9d93-6bdf32768466
md"""
### M√©todo de Golub‚ÄìKahan

El algoritmo de Golub‚ÄìKahan para calcular la SVD de una matriz $A \in \mathbb{R}^{m \times n}$ (con $m \geq n$) consta de dos fases principales:

#### Paso a paso
##### üîπ Paso 1: Reducci√≥n bidiagonal

El primer paso transforma la matriz original $A$ en una matriz **bidiagonal** $B$, es decir, una matriz con ceros fuera de la diagonal y la superdiagonal:

$B = U_1^T A V_1$

Este paso se logra aplicando **transformaciones ortogonales de Householder** por la izquierda y la derecha, que eliminan progresivamente los elementos debajo de la diagonal y fuera de la banda bidiagonal.

La estructura resultante tiene la forma:

$B = \begin{bmatrix}
d_1 & f_1 &        &        & \\
    & d_2 & f_2    &        & \\
    &     & \ddots & \ddots & \\
    &     &        & d_{n-1} & f_{n-1} \\
    &     &        &        & d_n
\end{bmatrix}$

Donde $d_i$ son los elementos diagonales y $f_i$ los elementos de la superdiagonal.

Este paso convierte el problema general en uno estructurado, sin alterar los valores singulares, y adem√°s **preserva la estabilidad num√©rica**.

##### üîπ Paso 2: Diagonalizaci√≥n bidiagonal (iteraci√≥n QR sim√©trica)

Una vez reducida $A$ a bidiagonal, el siguiente objetivo es transformar $B$ en una matriz **diagonal**, es decir, eliminar su superdiagonal sin perturbar la estructura.

Para esto se emplea una versi√≥n adaptada del **algoritmo QR sim√©trico con desplazamiento**. En lugar de formar $B^T B$ (que ser√≠a tridiagonal), se trabaja directamente sobre $B$ aplicando secuencias de **rotaciones de Givens** que eliminan progresivamente los elementos $f_i$.

Cada iteraci√≥n consta de:

1. C√°lculo de un **desplazamiento (shift)** aproximado del valor singular, basado en el extremo de la banda bidiagonal.
2. Aplicaci√≥n de rotaciones alternadas por la derecha e izquierda (tipo QR sim√©trico impl√≠cito) para "empujar" el elemento fuera de banda hacia la esquina inferior.
3. Eliminaci√≥n (o reducci√≥n por deflaci√≥n) cuando alg√∫n $f_i$ es suficientemente peque√±o en magnitud.

Este proceso se repite hasta que toda la superdiagonal de $B$ se anula, y la matriz resultante se convierte en la matriz $\Sigma$ de la SVD. Las rotaciones aplicadas se acumulan en matrices ortogonales $U_2$ y $V_2$.


##### üîπ Paso 3: Composici√≥n final

Finalmente, la SVD completa de $A$ se reconstruye a partir de las transformaciones aplicadas:

$A = U \Sigma V^T, \quad \text{donde } U = U_1 U_2,\quad V = V_1 V_2$

En esta descomposici√≥n:
- la matriz $\Sigma$ es una matriz diagonal con los valores singulares ordenados,
- las matrices $U$ y $V$ son ortogonales, y
- el proceso es **estable**, ya que todas las operaciones se realizan con transformaciones ortogonales.

"""

# ‚ïî‚ïê‚ï° c0b961d8-3400-4d21-a6ba-3953f48accd8
md"
## ü§ñ Implementaciones
"

# ‚ïî‚ïê‚ï° 5584e9c6-ddff-4f96-a32e-fc0a9309617a
md"
### Funciones auxiliares
"

# ‚ïî‚ïê‚ï° 4b7d264c-0790-40a9-bf34-f7d1e31fcc41
"""
Analize si la matriz es ortogonal o no-
"""
function is_orthogonal(Q; atol=1e-12)
    n = size(Q, 2)
    return isapprox(Q' * Q, I(n), atol=atol)
end


# ‚ïî‚ïê‚ï° 6cd89edb-e55f-46bf-b6b1-39b2453cdf1e
"""
Reconstruye la matriz original A a partir de su descomposici√≥n SVD.
Recibe un objeto F retornado por la funci√≥n svd(A).
Devuelve A ‚âà U * Œ£ * V·µÄ
"""
function reconstruct_from_svd(F)
    m, n = size(F.U, 1), size(F.V, 1)
    Œ£ = zeros(m, n)
    for i in 1:length(F.S)
        Œ£[i, i] = F.S[i]
    end
    return F.U * Œ£ * F.V'
end

# ‚ïî‚ïê‚ï° ea4159af-a82d-40b2-ace2-c689aaeecd0d
"""
Valida una descomposici√≥n SVD comparando la matriz original A
con su reconstrucci√≥n desde la tupla o estructura SVD `F`.

Imprime la norma del error ‚ÄñA - UŒ£V·µÄ‚Äñ‚ÇÇ.
"""
function validate_svd(A::Matrix{Float64}, F)
    A_hat = reconstruct_from_svd(F)
    error = norm(A - A_hat)
    println("Error de reconstrucci√≥n ‚ÄñA - UŒ£V·µÄ‚Äñ‚ÇÇ = ", error)
    return error
end


# ‚ïî‚ïê‚ï° 8b67358e-800f-4bf9-8869-90b29612e51e
struct SVDReconstruction
    U::Matrix{Float64}
    S::Vector{Float64}
    V::Matrix{Float64}
end


# ‚ïî‚ïê‚ï° beac433a-c1f4-4191-899f-6eb37d929889
example = randn(5, 3)

# ‚ïî‚ïê‚ï° aab73b0c-4d6e-467e-aaf8-93d8456508bc
md"
### SVD nativo de Julia
Utilizamos la funci√≥n `LinearAlgebra.svd`
"

# ‚ïî‚ïê‚ï° bb27217f-4d64-4e47-946d-65a4590226ea
svd

# ‚ïî‚ïê‚ï° e2d4f475-165a-47dc-a4ab-1e9b1f97be3f
md"#### Ejemplo"

# ‚ïî‚ïê‚ï° f2d58441-03af-4efb-9ad5-f3628511d7fa
F1 = svd(example, full=true)

# ‚ïî‚ïê‚ï° c7b2ba31-3e8a-4c66-8583-d7817bf53e1b
reconstruct_from_svd(F1)

# ‚ïî‚ïê‚ï° d804ab81-03bb-4770-a508-d58dc204de2b
validate_svd(example, F1)

# ‚ïî‚ïê‚ï° b6b0df75-1ffa-44bb-9b74-518bb918e8ab
md"### M√©todo ingenuo"

# ‚ïî‚ïê‚ï° 5655e762-fc65-48da-a4d8-9bbf0cf5e3fc
"""
Calcula la SVD de A utilizando el enfoque cl√°sico basado en formar C = A·µÄA.
Paso 1: Formar C = A·µÄA
Paso 2: Calcular la descomposici√≥n espectral de C = VŒõV·µÄ usando QR sim√©trico
Paso 3: Calcular AV = QR para obtener U
Devuelve U, Œ£, V·µÄ
"""
function svd_via_ata(A::Matrix{Float64})
    m, n = size(A)

    # Step 1: Form the symmetric matrix C = A·µÄA
    C = A' * A

    # Step 2: Compute eigen-decomposition of C = VŒõV·µÄ
    # This corresponds to applying the symmetric QR algorithm to C
    quadratic_eigenvalues, V = eigen(Symmetric(C))
    eigenvalues = sqrt.(clamp.(quadratic_eigenvalues, 0.0, Inf))

    # Step 3: Compute AV = QR to obtain U
    AV = A * V
    Q, _ = qr(AV)  # QR
    U = collect(Q) # Get full Q

    return SVDReconstruction(U, eigenvalues, V)
end

# ‚ïî‚ïê‚ï° 59f9f7e8-f355-40a3-94e0-5cb3c6dec15d
md"#### Ejemplo "

# ‚ïî‚ïê‚ï° 40a0849e-6ad5-4b70-b708-5cb1d92ed578
F2 = svd_via_ata(example)

# ‚ïî‚ïê‚ï° 6363a2cf-a7bf-475b-8f9c-0de2c5c66697
reconstruct_from_svd(F2)

# ‚ïî‚ïê‚ï° 08313203-f0ae-4603-be49-a85da9ffe178
validate_svd(example,F2)

# ‚ïî‚ïê‚ï° 247c0f32-0141-424f-9e8d-6dda19a521db
md"""
### M√©todo de Golub‚ÄìKahan
#### Funciones auxiliares
"""

# ‚ïî‚ïê‚ï° 311a1fdd-e0cc-413a-81c5-262e29a1132b
md"
#### Paso de Golub-Kahan"

# ‚ïî‚ïê‚ï° d5e98c9e-92ee-454d-9de8-7c5f38e89c68
"""
Calcula el shift de Wilkinson (mu) a partir de los tres elementos finales de B bidiagonal.

Inputs:
- dm: elemento d_{n-1} (pen√∫ltimo de la diagonal)
- fm: elemento f_{n-1} (√∫ltimo de la superdiagonal)
- dn: elemento d_n (√∫ltimo de la diagonal)

Output:
- mu: shift de Wilkinson
"""
function wilkinson_shift(dm::Float64, fm::Float64, dn::Float64)
    tmm = dm^2 + fm^2
    tmn = fm * dn
    tnn = dn^2

    Œ¥ = (tmm - tnn) / 2
    denom = abs(Œ¥) + sqrt(Œ¥^2 + tmn^2)

    if denom == 0
        return tnn
    else
        return tnn - sign(Œ¥) * tmn^2 / denom
    end
end


# ‚ïî‚ïê‚ï° 7902449e-e1ca-4dd7-aef1-96d32e051f40
"""
Devuelve (c, s, r) tal que [c s; -s c] * [y; z] = [r; 0]
"""
function givens_rotation(y::Float64, z::Float64)
    if z == 0
        return (1.0, 0.0, y)
    elseif y == 0
        return (0.0, 1.0, z)
    else
        r = hypot(y, z)
        return (y / r, z / r, r)
    end
end


# ‚ïî‚ïê‚ï° adba5d98-0080-4d56-81ca-897d8a97eb39
"""
Aplica un paso QR bidiagonal de Golub‚ÄìKahan a una matriz bidiagonal superior B ‚àà ‚Ñù^{n√ón}.

- B debe tener solo elementos en la diagonal y superdiagonal.
- La estructura bidiagonal se preserva.
- La transformaci√≥n es ortogonal y mantiene aproximadamente los autovalores de B·µóB.

Modifica B in-place.
"""
function golub_kahan_svd_step_matrix!(B::Matrix{Float64})
    n = size(B, 1)
    @assert size(B, 2) == n

    # Calcular el shift de Wilkinson
    d = diag(B)
    f = [B[i, i+1] for i in 1:n-1]
    Œº = wilkinson_shift(d[end-1], f[end], d[end])

    # Inicializar el primer vector para la rotaci√≥n por la derecha
    y = d[1]^2 - Œº
    z = d[1] * B[1, 2]

    for k in 1:n-1
        # -------- Rotaci√≥n por la derecha (columnas k, k+1) --------
        c, s, _ = givens_rotation(y, z)

        # Solo columnas k y k+1 de filas k y siguientes (preservar estructura)
        for i in k:n
            t1 = B[i, k]
            t2 = B[i, k+1]
            B[i, k]   =  c * t1 + s * t2
            B[i, k+1] = -s * t1 + c * t2
        end

        # -------- Rotaci√≥n por la izquierda (filas k, k+1) --------
        y = B[k, k]
        z = B[k+1, k]
        c, s, _ = givens_rotation(y, z)

        # Solo filas k y k+1 de columnas k y siguientes
        for j in k:n
            t1 = B[k, j]
            t2 = B[k+1, j]
            B[k, j]   =  c * t1 + s * t2
            B[k+1, j] = -s * t1 + c * t2
        end

        # Preparar vector (y, z) para la pr√≥xima rotaci√≥n por la derecha
        if k < n - 1
            y = B[k, k+1]
            z = B[k, k+2]
        end
    end

    # Limpiar num√©ricamente la matriz fuera de la banda bidiagonal
    for i in 1:n
        for j in 1:n
            if j ‚â† i && j ‚â† i+1
                B[i, j] = 0.0
            end
        end
    end

    return B
end


# ‚ïî‚ïê‚ï° 7f39475d-a3c9-4c5c-8a55-aa2ba34d6289
md"##### Validaci√≥n"


# ‚ïî‚ïê‚ï° c2105a86-9dda-4ccb-a9df-cba3c10b6161
"""
Construye una matriz bidiagonal superior B ‚àà ‚Ñù^{n√ón} a partir de:

- d: diagonal de B, longitud n
- f: superdiagonal de B, longitud n - 1

Retorna: B :: Matrix{Float64}, una matriz n√ón con estructura bidiagonal superior.
"""
function build_bidiagonal(d, f)
    n = length(d)
    @assert length(f) == n - 1 "La superdiagonal f debe tener longitud n - 1"

    B = zeros(Float64, n, n)

    for i in 1:n
        B[i, i] = d[i]
        if i < n
            B[i, i+1] = f[i]
        end
    end

    return B
end


# ‚ïî‚ïê‚ï° 8ca30862-249a-444d-8a79-702ec8732935
"""
Compara `wilkinson_shift` con el verdadero autovalor de una matriz 2x2 para validar.
"""
function validate_shift(dm, fm, dn)
    T = [
        dm^2 + fm^2    fm * dn
        fm * dn        dn^2
    ]
    Œª = eigen(T).values
    Œº_ref = Œª[argmin(abs.(Œª .- dn^2))]  # autovalor m√°s cercano a t_nn
    Œº_custom = wilkinson_shift(dm, fm, dn)
    
    println("Œº (eigen 2√ó2)     = $Œº_ref")
    println("Œº (Wilkinson calc)= $Œº_custom")
    println("Error             = $(abs(Œº_custom - Œº_ref))")
end


# ‚ïî‚ïê‚ï° a1c28c45-10de-460c-909f-ab724f2afd45
"""
Valida un paso de Golub‚ÄìKahan aplicado a una matriz bidiagonal B.

- step_func: funci√≥n que modifica B in-place (como golub_kahan_svd_step_matrix!)
- B: matriz bidiagonal cuadrada (con solo diagonal y superdiagonal)

Opcional:
- verbose = true: imprime detalles
- atol: tolerancia para comparar autovalores

Retorna: true si todo pasa, false si falla alguna prueba.
"""
function validate_golub_kahan_step(step_func::Function, B::Matrix{Float64};
                                   atol=1e-10, verbose=true)
    n = size(B, 1)
    @assert size(B, 2) == n "B debe ser cuadrada"

    # --- Copiar datos originales ---
    B_before = copy(B)
    T_before = B_before' * B_before
    Œª_before = sort(eigvals(Symmetric(T_before)))

    # --- Aplicar paso QR bidiagonal ---
    step_func(B)

    # --- Verificar estructura bidiagonal ---
    is_bidiagonal = all(i == j || j == i+1 || B[i, j] == 0.0 for i in 1:n, j in 1:n)

    # --- Comparar autovalores ---
    T_after = B' * B
    Œª_after = sort(eigvals(Symmetric(T_after)))
    Œª_diff = norm(Œª_before - Œª_after, Inf)

    # --- Imprimir si se desea ---
    if verbose
        println("‚úî Estructura bidiagonal: ", is_bidiagonal)
        println("‚úî Autovalores antes:  ", round.(Œª_before, digits=8))
        println("‚úî Autovalores despu√©s:", round.(Œª_after, digits=8))
        println("ŒîŒª ‚àû-norm: ", Œª_diff)
    end

    return is_bidiagonal && Œª_diff ‚â§ atol
end


# ‚ïî‚ïê‚ï° 8ec72b94-d090-4c76-bde4-70787a67461a
validate_golub_kahan_step(
	golub_kahan_svd_step_matrix!, 
	build_bidiagonal(
		[1.0, 2.0, 3.0, 4.0], 
		[1.0, 1.0, 0.01]
	)
)

# ‚ïî‚ïê‚ï° e344fe0e-b939-4163-84ac-01c402895e38
md"#### Diagonalizaci√≥n"

# ‚ïî‚ïê‚ï° b2928cde-9e9b-4d28-8a0a-45bae8e8f4ef
"""
Applies the full Golub‚ÄìKahan SVD iteration (Algorithm 8.6.2) on a real upper bidiagonal matrix B.

This function repeatedly applies the Golub‚ÄìKahan SVD step with Wilkinson shift to deflate
the superdiagonal of B until it becomes numerically zero (i.e., diagonalizes B).

The bidiagonal structure is preserved, and the function modifies B in-place.

Inputs:
- B::Matrix{Float64}: square upper bidiagonal matrix (with only diagonal and superdiagonal)
- œµ: relative tolerance for deflation (default: 100 √ó eps(Float64))

Output:
- B is modified in-place to become diagonal (approximate singular values on the diagonal)
"""
function golub_kahan_svd_matrix!(B::Matrix{Float64}; œµ = 100 * eps(Float64))
    n = size(B, 1)
    @assert size(B, 2) == n "B must be square"
    
    while true
        # Step 1: deflation ‚Äî set small superdiagonal entries to zero
        for i in 1:n-1
            d1 = abs(B[i, i])
            d2 = abs(B[i+1, i+1])
            tol = œµ * (d1 + d2)
            if abs(B[i, i+1]) ‚â§ tol
                B[i, i+1] = 0.0
            end
        end

        # Step 2: find the largest q such that B[q-1, q] ‚â† 0
        q = n
        while q > 1 && B[q-1, q] == 0.0
            q -= 1
        end

        if q == 1
            break  # Fully diagonalized
        end

        # Step 3: find the smallest p such that B[p-1, p] == 0
        p = q - 1
        while p > 1 && B[p-1, p] ‚â† 0.0
            p -= 1
        end

        # Step 4: handle zeros on the diagonal
        zero_on_diag = false
        maxd = maximum(abs.(diag(B)))
        for i in p:q
            if abs(B[i, i]) ‚â§ œµ * maxd
                zero_on_diag = true
                break
            end
        end

        if zero_on_diag
            for i in p:q-1
                if abs(B[i, i]) ‚â§ œµ * maxd
                    B[i, i+1] = 0.0
                end
            end
        elseif q - p + 1 ‚â• 2
            # Step 5: apply one Golub‚ÄìKahan step to the active block
            Bblock = B[p:q, p:q]
            golub_kahan_svd_step_matrix!(Bblock)
            B[p:q, p:q] .= Bblock
        end
    end

    return B
end


# ‚ïî‚ïê‚ï° 502c0650-1925-4174-8c8e-dd963728c7b2
md"##### Validaci√≥n"

# ‚ïî‚ïê‚ï° b4276865-6a07-484a-9290-7d557af8ac88
"""
Verifica la correcci√≥n de golub_kahan_svd_matrix! sobre una matriz bidiagonal B.

- B: matriz bidiagonal cuadrada (modificada in-place)
- atol: tolerancia absoluta sobre errores espectrales y fuera de la diagonal
- verbose: si true, imprime diferencias y estructura

Retorna: true si todo est√° correcto, false si falla alguna validaci√≥n.
"""
function validate_golub_kahan_svd_matrix(B::Matrix{Float64}; atol=1e-10, verbose=true)
    n = size(B, 1)
    @assert size(B, 2) == n "B debe ser cuadrada"

    # Copia para comparar
    B0 = copy(B)
    Œª0 = sort(eigvals(Symmetric(B0' * B0)))

    # Ejecutar algoritmo
    golub_kahan_svd_matrix!(B)

    # Verificaci√≥n 1: la matriz resultante debe ser diagonal (bidiagonal con superdiagonal ‚âà 0)
    is_diagonal = all(abs(B[i, j]) ‚â§ atol for i in 1:n, j in 1:n if i ‚â† j)

    # Verificaci√≥n 2: los autovalores de B·µóB deben conservarse
    Œªf = sort(eigvals(Symmetric(B' * B)))
    Œª_diff = norm(Œª0 - Œªf, Inf)

    # Verificaci√≥n 3: valores singulares ordenados (opcional)
    œÉ = sort(abs.(diag(B)), rev=true)

    if verbose
        println("‚úî Diagonal final: ", is_diagonal)
        println("‚úî Autovalores iniciales: ", round.(Œª0, digits=8))
        println("‚úî Autovalores finales:   ", round.(Œªf, digits=8))
        println("ŒîŒª ‚àû-norm: ", Œª_diff)
        println("‚úî Valores singulares:    ", round.(œÉ, digits=8))
    end

    return is_diagonal && Œª_diff ‚â§ atol
end


# ‚ïî‚ïê‚ï° c756f929-8da9-41f6-aa58-6247d2a57acb
validate_golub_kahan_svd_matrix(
	build_bidiagonal(
		[1.0, 2.0, 3.0, 4.0],
		[1.0, 1.0, 0.01]
	)
)

# ‚ïî‚ïê‚ï° 3069c786-0823-42a0-92c0-4df61174e5d1
md"
Podemos ver que los autovalores parecen conservarse en las validaciones de `golub_kahan_svd_step_matrix` y `golub_kahan_svd_matrix`. Sin embargo la norma del error es demasiado grande. Esto nos dice que no es un problema de la l√≥gica del algoritmo, sino de su implementaci√≥n.
Por esto, creemos otra implementaci√≥n que utilice la matriz bidiagonal de manera impl√≠cita.
"

# ‚ïî‚ïê‚ï° 04eb9c27-8a4f-462e-930a-4f643d424769
md"#### Algoritmo de Golub Kahan"

# ‚ïî‚ïê‚ï° 4e69684e-b6bb-439a-a8c7-3a65ebb36f25
"""
Reduce la matriz A a forma bidiagonal utilizando reflexiones de Householder.
Devuelve la matriz bidiagonal B, y las matrices ortogonales U y V tal que A ‚âà U * B * V·µÄ.
"""
function bidiagonalize_householder(A::Matrix{Float64})
    m, n = size(A)
    B = copy(A)
    U = Matrix{Float64}(I, m, m)
    V = Matrix{Float64}(I, n, n)

    for i in 1:min(m, n)
        # Reflexi√≥n de Householder desde la izquierda (columnas)
        x = B[i:end, i]
        v = copy(x)
        v[1] += sign(x[1]) * norm(x)
        v = v / norm(v)
        B[i:end, i:end] -= 2 * v * (v' * B[i:end, i:end])
        U[:, i:end] -= 2 * (U[:, i:end] * v) * v'

        if i < n
            # Reflexi√≥n de Householder desde la derecha (filas)
            x = B[i, i+1:end]'
            v = copy(x)
            v[1] += sign(x[1]) * norm(x)
            v = v / norm(v)
            B[i:end, i+1:end] -= 2 * (B[i:end, i+1:end] * v') * v
            V[:, i+1:end] -= 2 * (V[:, i+1:end] * v') * v
        end
    end

    return B, U, V
end


# ‚ïî‚ïê‚ï° cfa62a92-828e-4510-81ae-985e84e2250e
"""
Fuerza a cero los elementos de la matriz B que est√°n fuera de la banda bidiagonal,
si su magnitud es menor que un umbral dado (por defecto 1e-14).
Esto es √∫til para limpiar errores num√©ricos tras la bidiagonalizaci√≥n.

Modifica B in-place.
"""
function force_bidiagonal!(B::Matrix{Float64}; atol=1e-14)
    m, n = size(B)
    for i in 1:m
        for j in 1:n
            if j != i && j != i+1 && abs(B[i,j]) < atol
                B[i,j] = 0.0
            end
        end
    end
end


# ‚ïî‚ïê‚ï° c1a1f0f7-39a9-4597-9c1e-3358b0ee232d
begin
	Y = randn(5, 3)
	B, U, V = bidiagonalize_householder(Y)
	A_hat = U * B * V'
	println("Error de reconstrucci√≥n: ", norm(Y - A_hat))
	
end

# ‚ïî‚ïê‚ï° d8888165-0100-4c40-8bd1-0182f91e3565
begin
	
	function is_bidiagonal(B; atol=1e-12)
	    m, n = size(B)
	    for i in 1:m
	        for j in 1:n
	            if (j != i && j != i+1) && abs(B[i,j]) > atol
	                return false
	            end
	        end
	    end
	    return true
	end
	
	@show is_bidiagonal(B)
end

# ‚ïî‚ïê‚ï° 65aa59c8-586f-4850-875c-7a19ed968882
"""
Calcula la SVD de una matriz A ‚àà ‚Ñù^{m√ón} utilizando el algoritmo de Golub-Kahan.
Paso 1: Bidiagonalizaci√≥n de A usando reflexiones de Householder.
Paso 2: Diagonalizaci√≥n iterativa de la matriz bidiagonal mediante rotaciones de Givens.
Devuelve U, Œ£, V·µÄ
"""
function svd_golub_kahan(A::Matrix{Float64}; tol=1e-12, maxiter=1000)
    m, n = size(A)
    B, U, V = bidiagonalize_householder(A)
	force_bidiagonal!(B)
	B = B[1:n, 1:n]
    golub_kahan_svd_matrix!(B)
	display(B)
    Œ£ = zeros(m, n)
    for i in 1:min(m,n)
        Œ£[i,i] = abs(B[i,i])
    end

    return SVDReconstruction(U, diag(Œ£), V')
end


# ‚ïî‚ïê‚ï° 6c502074-cfa6-4d7d-8754-b4114743aaeb
md"#### Ejemplo y validaci√≥n"

# ‚ïî‚ïê‚ï° 537968ea-5d8c-4adc-9f36-d229e21d4085
begin
	F3 = svd_golub_kahan(example)
	validate_svd(example,F3)
end

# ‚ïî‚ïê‚ï° 4f81f155-f5c7-42f2-8e10-af8ae8ad1dae
A_reconstructed = reconstruct_from_svd(F3)

# ‚ïî‚ïê‚ï° ab104798-39bf-44cb-ad07-9d5592524730
md" ### Funciones auxiliares extra"

# ‚ïî‚ïê‚ï° d79631a6-4494-49bd-a9e5-8b100de0272d
"""
Aplica rotaci√≥n de Givens por la derecha sobre d[k] y f[k]
"""
function apply_right_rotation!(d, f, k::Int, c::Float64, s::Float64)
    d_k  = d[k]
    f_k  = f[k]
    d[k] =  c * d_k + s * f_k
    f[k] = -s * d_k + c * f_k
end


# ‚ïî‚ïê‚ï° 2edc23a7-b981-4416-8516-54084054bd74
"""
Aplica rotaci√≥n de Givens por la izquierda sobre d[k] y d[k+1]
"""
function apply_left_rotation!(d, k::Int, c::Float64, s::Float64)
    d_k  = d[k]
    d_k1 = d[k+1]
    d[k]   =  c * d_k + s * d_k1
    d[k+1] = -s * d_k + c * d_k1
end


# ‚ïî‚ïê‚ï° a48dea5f-3e17-45d2-9a07-7eb0228ca516
"""
Diagonaliza la matriz bidiagonal B utilizando rotaciones de Givens
y acumula las transformaciones en U y V.
Modifica B, U y V in-place.
"""
function diagonalize_bidiagonal!(B::Matrix{Float64}, U::Matrix{Float64}, V::Matrix{Float64};
                                  tol=1e-12, maxiter=1000)

    m, n = size(B)
    for iter = 1:maxiter
        converged = true

        for i in 1:n-1
            # Verifica si el elemento fuera de la diagonal es significativo
            if abs(B[i, i+1]) > tol * (abs(B[i,i]) + abs(B[i+1,i+1]))
                converged = false

                # Paso 1: rotaci√≥n a la derecha (columna i e i+1 de B y V)
                x = B[i,i]^2 - B[i+1,i+1]^2
                y = B[i,i] * B[i,i+1]
                c, s = givens_rotation(x, y)

                apply_right_rotation!(B, i, i+1, c, s)
                apply_right_rotation!(V, i, i+1, c, s)

                # Paso 2: rotaci√≥n a la izquierda (fila i e i+1 de B y U)
                c, s = givens_rotation(B[i,i], B[i+1,i])
                apply_left_rotation!(B, i, i+1, c, s)
                apply_right_rotation!(U, i, i+1, c, s)
            end
        end

        if converged
            break
        end
    end
end


# ‚ïî‚ïê‚ï° a0b20c8f-64dd-4966-87c3-ba4156ebdbf2
md"##### Ejemplo"

# ‚ïî‚ïê‚ï° 78ad67b1-5ead-4d3e-b5bb-062907f524f5
md"---"

# ‚ïî‚ïê‚ï° 277c10ee-bd03-4efe-b54b-0d835a8781a0
md"### Old: üëæ M√©todo impl√≠cito"

# ‚ïî‚ïê‚ï° 9a929fc1-a2b2-474a-9deb-4d8a6bc6d7d1
"""
Computa los valores singulares de una matriz A ‚àà ‚Ñù^{m√ón} (con m ‚â• n)
usando la descomposici√≥n bidiagonal seguida de la iteraci√≥n QR impl√≠cita
(Golub‚ÄìKahan, Algoritmo 8.6.2 de Golub y Van Loan).

No acumula U ni V expl√≠citamente (solo valores singulares).
"""
function svd_golub_kahan_values(A::Matrix{Float64}; œµ = 100 * eps(Float64))
    m, n = size(A)
    @assert m ‚â• n "Se requiere m ‚â• n"

    # Paso 1: Reducci√≥n bidiagonal A = U‚ÇÅ * B * V‚ÇÅ·µó
    B_full = copy(A)
    U1 = Matrix{Float64}(I, m, m)
    V1 = Matrix{Float64}(I, n, n)
    LinearAlgebra.bidiagonalize!(B_full, U1, V1)

    # Extraer la bidiagonal B
    d = diag(B_full[1:n, 1:n])           # diagonal
    f = [B_full[i, i+1] for i in 1:n-1]  # superdiagonal

    # Paso 2: Iteraci√≥n QR impl√≠cita sobre (d, f)
    function is_converged(f, d)
        all(abs(f[i]) ‚â§ œµ * (abs(d[i]) + abs(d[i+1])) for i in 1:length(f))
    end

    while !is_converged(f, d)
        golub_kahan_svd_step!(d, f)
    end

    # Retornar valores singulares ordenados
    return sort(abs.(d); rev=true)
end


# ‚ïî‚ïê‚ï° cb27deb4-cefa-4d34-b29f-be8fd219035d
md"""begin
	# Matriz de prueba
	A = randn(6, 4)
	
	# SVD por Golub‚ÄìKahan impl√≠cito (solo valores singulares)
	œÉ = svd_golub_kahan_values(A)
	
	# SVD de referencia usando la funci√≥n est√°ndar de Julia
	œÉ_ref = svd(A).S
	
	# Mostrar resultados
	println("œÉ (GK impl√≠cito) = ", round.(œÉ, digits=6))
	println("œÉ (referencia)   = ", round.(œÉ_ref, digits=6))
	println("Error absoluto    = ", round.(maximum(abs.(œÉ .- œÉ_ref)), digits=6))
	
end"""

# ‚ïî‚ïê‚ï° 00ca8f64-6937-45ee-8970-d1c2bf49fd59
md"
## To Do:
- [X] Have a working Golub
* - [ ] Full algorithm (From initial Householder)
* - [x] Make a verification function
* - [ ] How to get the SVD from the result?
- [ ] Add or transform into a `Bidiagonal` version (does it count as implicit?)
- [X] Add other implementation (either classical or Jacobi)
     -> Comparar con versi√≥n INGENUA, no cl√°sica.
"

# ‚ïî‚ïê‚ï° 00000000-0000-0000-0000-000000000001
PLUTO_PROJECT_TOML_CONTENTS = """
[deps]
LinearAlgebra = "37e2e46d-f89d-539d-b4ee-838fcccc9c8e"
"""

# ‚ïî‚ïê‚ï° 00000000-0000-0000-0000-000000000002
PLUTO_MANIFEST_TOML_CONTENTS = """
# This file is machine-generated - editing it directly is not advised

julia_version = "1.11.1"
manifest_format = "2.0"
project_hash = "ac1187e548c6ab173ac57d4e72da1620216bce54"

[[deps.Artifacts]]
uuid = "56f22d72-fd6d-98f1-02f0-08ddc0907c33"
version = "1.11.0"

[[deps.CompilerSupportLibraries_jll]]
deps = ["Artifacts", "Libdl"]
uuid = "e66e0078-7015-5450-92f7-15fbd957f2ae"
version = "1.1.1+0"

[[deps.Libdl]]
uuid = "8f399da3-3557-5675-b5ff-fb832c97cbdb"
version = "1.11.0"

[[deps.LinearAlgebra]]
deps = ["Libdl", "OpenBLAS_jll", "libblastrampoline_jll"]
uuid = "37e2e46d-f89d-539d-b4ee-838fcccc9c8e"
version = "1.11.0"

[[deps.OpenBLAS_jll]]
deps = ["Artifacts", "CompilerSupportLibraries_jll", "Libdl"]
uuid = "4536629a-c528-5b80-bd46-f80d51c5b363"
version = "0.3.27+1"

[[deps.libblastrampoline_jll]]
deps = ["Artifacts", "Libdl"]
uuid = "8e850b90-86db-534c-a0d3-1478176c7d93"
version = "5.11.0+0"
"""

# ‚ïî‚ïê‚ï° Cell order:
# ‚ïü‚îÄa58e9c22-51a1-11f0-0fc0-914efb421b18
# ‚ï†‚ïê701241c2-322f-45ca-b17d-437cf32a7ff3
# ‚ïü‚îÄ11b2ebb7-626e-49c1-a294-c9b834c73bdb
# ‚ïü‚îÄ6b68d0ac-8118-44aa-940e-5a807217e562
# ‚ïü‚îÄ56ef11c7-1b71-45f7-b286-38a932ac3dc4
# ‚ïü‚îÄdbb9e53d-bb68-4220-a32d-6c3ce32e274a
# ‚ïü‚îÄ85c6df45-20ef-4db2-8703-ddf76166832e
# ‚ïü‚îÄ74470dd1-eb43-4039-9d93-6bdf32768466
# ‚ïü‚îÄc0b961d8-3400-4d21-a6ba-3953f48accd8
# ‚ïü‚îÄ5584e9c6-ddff-4f96-a32e-fc0a9309617a
# ‚ïü‚îÄ4b7d264c-0790-40a9-bf34-f7d1e31fcc41
# ‚ïü‚îÄ6cd89edb-e55f-46bf-b6b1-39b2453cdf1e
# ‚ïü‚îÄea4159af-a82d-40b2-ace2-c689aaeecd0d
# ‚ï†‚ïê8b67358e-800f-4bf9-8869-90b29612e51e
# ‚ï†‚ïêbeac433a-c1f4-4191-899f-6eb37d929889
# ‚ïü‚îÄaab73b0c-4d6e-467e-aaf8-93d8456508bc
# ‚ïü‚îÄbb27217f-4d64-4e47-946d-65a4590226ea
# ‚ïü‚îÄe2d4f475-165a-47dc-a4ab-1e9b1f97be3f
# ‚ïü‚îÄf2d58441-03af-4efb-9ad5-f3628511d7fa
# ‚ïü‚îÄc7b2ba31-3e8a-4c66-8583-d7817bf53e1b
# ‚ïü‚îÄd804ab81-03bb-4770-a508-d58dc204de2b
# ‚ïü‚îÄb6b0df75-1ffa-44bb-9b74-518bb918e8ab
# ‚ïü‚îÄ5655e762-fc65-48da-a4d8-9bbf0cf5e3fc
# ‚ïü‚îÄ59f9f7e8-f355-40a3-94e0-5cb3c6dec15d
# ‚ïü‚îÄ40a0849e-6ad5-4b70-b708-5cb1d92ed578
# ‚ïü‚îÄ6363a2cf-a7bf-475b-8f9c-0de2c5c66697
# ‚ïü‚îÄ08313203-f0ae-4603-be49-a85da9ffe178
# ‚ïü‚îÄ247c0f32-0141-424f-9e8d-6dda19a521db
# ‚ïü‚îÄd5e98c9e-92ee-454d-9de8-7c5f38e89c68
# ‚ïü‚îÄ7902449e-e1ca-4dd7-aef1-96d32e051f40
# ‚ïü‚îÄc2105a86-9dda-4ccb-a9df-cba3c10b6161
# ‚ïü‚îÄ8ca30862-249a-444d-8a79-702ec8732935
# ‚ïü‚îÄ311a1fdd-e0cc-413a-81c5-262e29a1132b
# ‚ï†‚ïêadba5d98-0080-4d56-81ca-897d8a97eb39
# ‚ïü‚îÄ7f39475d-a3c9-4c5c-8a55-aa2ba34d6289
# ‚ïü‚îÄa1c28c45-10de-460c-909f-ab724f2afd45
# ‚ï†‚ïê8ec72b94-d090-4c76-bde4-70787a67461a
# ‚ïü‚îÄe344fe0e-b939-4163-84ac-01c402895e38
# ‚ïü‚îÄb2928cde-9e9b-4d28-8a0a-45bae8e8f4ef
# ‚ïü‚îÄ502c0650-1925-4174-8c8e-dd963728c7b2
# ‚ïü‚îÄb4276865-6a07-484a-9290-7d557af8ac88
# ‚ï†‚ïêc756f929-8da9-41f6-aa58-6247d2a57acb
# ‚ïü‚îÄ3069c786-0823-42a0-92c0-4df61174e5d1
# ‚ïü‚îÄ04eb9c27-8a4f-462e-930a-4f643d424769
# ‚ïü‚îÄ4e69684e-b6bb-439a-a8c7-3a65ebb36f25
# ‚ïü‚îÄcfa62a92-828e-4510-81ae-985e84e2250e
# ‚ïü‚îÄc1a1f0f7-39a9-4597-9c1e-3358b0ee232d
# ‚ïü‚îÄd8888165-0100-4c40-8bd1-0182f91e3565
# ‚ïü‚îÄa48dea5f-3e17-45d2-9a07-7eb0228ca516
# ‚ïü‚îÄ65aa59c8-586f-4850-875c-7a19ed968882
# ‚ïü‚îÄ6c502074-cfa6-4d7d-8754-b4114743aaeb
# ‚ï†‚ïê4f81f155-f5c7-42f2-8e10-af8ae8ad1dae
# ‚ï†‚ïê537968ea-5d8c-4adc-9f36-d229e21d4085
# ‚ïü‚îÄab104798-39bf-44cb-ad07-9d5592524730
# ‚ïü‚îÄd79631a6-4494-49bd-a9e5-8b100de0272d
# ‚ïü‚îÄ2edc23a7-b981-4416-8516-54084054bd74
# ‚ïü‚îÄa0b20c8f-64dd-4966-87c3-ba4156ebdbf2
# ‚ïü‚îÄ78ad67b1-5ead-4d3e-b5bb-062907f524f5
# ‚ïü‚îÄ277c10ee-bd03-4efe-b54b-0d835a8781a0
# ‚ïü‚îÄ9a929fc1-a2b2-474a-9deb-4d8a6bc6d7d1
# ‚ïü‚îÄcb27deb4-cefa-4d34-b29f-be8fd219035d
# ‚ïü‚îÄ00ca8f64-6937-45ee-8970-d1c2bf49fd59
# ‚ïü‚îÄ00000000-0000-0000-0000-000000000001
# ‚ïü‚îÄ00000000-0000-0000-0000-000000000002

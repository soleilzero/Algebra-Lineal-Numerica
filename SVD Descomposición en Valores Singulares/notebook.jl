### A Pluto.jl notebook ###
# v0.20.3

using Markdown
using InteractiveUtils

# ‚ïî‚ïê‚ï° 701241c2-322f-45ca-b17d-437cf32a7ff3
using LinearAlgebra

# ‚ïî‚ïê‚ï° a58e9c22-51a1-11f0-0fc0-914efb421b18
md"""
# C√°lculo Num√©rico de la SVD: Algoritmo de Golub‚ÄìKahan

## √çndice
1. Objetivos
1. Introducci√≥n
1. Fundamentos te√≥ricos
3. Algoritmos
"""

# ‚ïî‚ïê‚ï° 11b2ebb7-626e-49c1-a294-c9b834c73bdb
md"
## Objetivos

Explicar y analizar detalladamente el algoritmo num√©rico para calcular la descomposici√≥n en valores singulares (SVD), con √©nfasis en el enfoque de Golub‚ÄìKahan basado en la reducci√≥n bidiagonal y la iteraci√≥n QR impl√≠cita.

* Exponer las conexiones te√≥ricas entre la SVD y los problemas de autovalores sim√©tricos,
* analizar el comportamiento num√©rico del algoritmo cl√°sico frente a m√©todos mal condicionados,
* implementar y visualizar los pasos clave del algoritmo de Golub‚ÄìKahan,
* discutir la eficiencia computacional y estrategias pr√°cticas.

En otro trabajo se puede aplicar la SVD computada num√©ricamente a un problema pr√°ctico.

## Introducci√≥n 

La descomposici√≥n en valores singulares (SVD) es una de las herramientas m√°s poderosas y vers√°tiles del √°lgebra lineal num√©rica.
No solo existe para cualquier matriz y proporciona informaci√≥n estructural sobre ella ‚Äîcomo su rango, condici√≥n y modos principales de acci√≥n‚Äî, sino que tambi√©n constituye la base de aplicaciones fundamentales en an√°lisis de datos, compresi√≥n, m√©todos de m√≠nimos cuadrados, y problemas inversos.

Desde el punto de vista computacional, calcular la SVD de una matriz general $\in \mathbb{R}^{m \times n}$ de forma precisa y eficiente requiere mucho m√°s que aplicar definiciones algebraicas. De hecho, formar matrices como $A^T A$ puede llevar a errores num√©ricos significativos. Para abordar este desaf√≠o, Golub y Kahan propusieron en 1965 un algoritmo robusto y eficiente basado en dos pasos clave:

1. **Reducci√≥n bidiagonal de $A$** mediante transformaciones de Householder.
2. **Diagonalizaci√≥n de la matriz bidiagonal** resultante usando una iteraci√≥n QR adaptada, que opera de forma impl√≠cita sobre $B^T B$, sin construirla expl√≠citamente.

Este notebook est√° dedicado al estudio detallado de este algoritmo. Nuestro objetivo no es solo entender c√≥mo se implementa, sino por qu√© funciona, c√≥mo se conecta con los problemas sim√©tricos de autovalores, y qu√© garant√≠as num√©ricas ofrece.

A lo largo de este recorrido, desarrollaremos teor√≠a, visualizaremos ejemplos peque√±os y construiremos bloques de c√≥digo que ilustran cada etapa del proceso. Este an√°lisis est√° inspirado en la secci√≥n 8.6 del libro *Matrix Computations*, de Golub y Van Loan, una referencia cl√°sica en el √°rea.

> **Requisitos previos**: se asume familiaridad con transformaciones ortogonales (Householder, Givens), descomposici√≥n QR, y problemas de autovalores sim√©tricos.

---
"

# ‚ïî‚ïê‚ï° 6b68d0ac-8118-44aa-940e-5a807217e562
md"
## Fundamentos te√≥ricos de la SVD
Definici√≥n y existencia

Propiedades b√°sicas

SVD y matrices sim√©tricas asociadas ?

Matriz aumentada sim√©trica

Implicaciones algor√≠tmicas

### üü¢ Definici√≥n y existencia de la SVD

Sea $A \in \mathbb{R}^{m \times n}$. La **descomposici√≥n en valores singulares (SVD)** de $A$ es una factorizaci√≥n de la forma:

$A = U \Sigma V^T,$

donde
- las matrices $U \in \mathbb{R}^{m \times m}$ y $V \in \mathbb{R}^{n \times n}$ son ortogonales,
- la matriz $\Sigma \in \mathbb{R}^{m \times n}$ es diagonal rectangular con entradas no negativas en la diagonal:
  
$\Sigma = \begin{bmatrix}
\sigma_1 & & & \\
& & \ddots & \\
& & & \sigma_r \\
& & & & 0 \\
\end{bmatrix}, 
\quad \text{con } \sigma_1 \geq \sigma_2 \geq \cdots \geq \sigma_r > 0,$

y $r = \operatorname{rank}(A)$.

Las cantidades $\sigma_i$ se llaman **valores singulares** de $A$, y son √∫nicos. Los vectores columna de $U$ y $V$ se llaman **vectores singulares izquierdos** y **derechos**, respectivamente.

#### ‚ùó Teorema de existencia

**Toda** matriz real \( A \in \mathbb{R}^{m \times n} \), sea cuadrada, rectangular, singular o no, **admite una descomposici√≥n SVD** como la descrita arriba.

Esto contrasta con la factorizaci√≥n espectral, que solo existe para matrices sim√©tricas.

#### üß† Intuici√≥n geom√©trica

La SVD describe la acci√≥n de la matriz $A$ como una transformaci√≥n que:

1. **Rota** el espacio fuente (a trav√©s de $V^T$),
2. **Escala** en direcciones ortogonales (a trav√©s de $\Sigma$),
3. **Rota** el espacio imagen (a trav√©s de $U$).

En otras palabras, toda matriz real lineal puede descomponerse como una secuencia de rotaciones/reflexiones y escalamientos. Esta intuici√≥n es presentada de manera gr√°fica por Visual Kernel en el Cap√≠tulo 1 Visualize Different Matrices de su colecci√≥n SEE Matrix.


"

# ‚ïî‚ïê‚ï° 56ef11c7-1b71-45f7-b286-38a932ac3dc4
md"""
### üü¢ Propiedades b√°sicas de la SVD

Dada la descomposici√≥n $A = U \Sigma V^T$ de una matriz $A \in \mathbb{R}^{m \times n}$, se cumplen las siguientes propiedades fundamentales:

#### üîπ Ortogonalidad de los vectores singulares

- Las **columnas de $V$** (vectores singulares derechos) son autovectores de $A^T A$ y forman una base ortonormal de $\mathbb{R}^m$.
- Las **columnas de $U$** (vectores singulares izquierdos) son autovectores de $A A^T$ y forman una base ortonormal de $\mathbb{R}^n$.


#### üîπ Interpretaci√≥n de los valores singulares

- Los **autovalores** de $A^T A$ y $A A^T$ son exactamente $\sigma_i^2$.
- Los valores singulares $\sigma_i$ son los **autovalores positivos** de $A^T A$ o $A A^T$:
  $A^T A = V \Sigma^2 V^T, \quad A A^T = U \Sigma^2 U^T$
- Siempre se ordenan de forma no creciente:
  $\sigma_1 \geq \sigma_2 \geq \cdots \geq \sigma_r > 0$
- Se cumple que $\text{rank}(A) = r = \# \{ \sigma_i > 0 \}$.

#### üîπ Normas y condici√≥n

- Norma 2:
  $\| A \|_2 = \sigma_1$
- Norma de Frobenius:
  $\| A \|_F = \left( \sum_{i=1}^r \sigma_i^2 \right)^{1/2}$
- N√∫mero de condici√≥n (si $A$ es cuadrada y de rango completo):
  $\kappa_2(A) = \frac{\sigma_1}{\sigma_r}$

#### üîπ Descomposici√≥n como suma de rangos 1

La descomposici√≥n SVD permite representar cualquier matriz $A \in \mathbb{R}^{m \times n}$ como una **suma de matrices de rango 1**:

$A = \sum_{i=1}^r \sigma_i u_i v_i^T,$

donde $r = \operatorname{rank}(A)$, $u_i$ y $v_i$ son los vectores singulares izquierdo y derecho correspondientes al valor singular $\sigma_i$, cada t√©rmino $\sigma_i u_i v_i^T$ es una matriz de **rango 1**.

Esta forma revela que la SVD descompone $A$ como la suma de **modos b√°sicos** ordenados por importancia (es decir, energ√≠a o norma).

##### üî∏ Aproximaci√≥n de rango bajo √≥ptima

Una de las propiedades m√°s poderosas de la SVD es que permite construir la **mejor aproximaci√≥n de rango $k$** a $A$ en sentido de m√≠nima distancia, tanto en norma 2 como en norma de Frobenius.

Para cualquier $k < r$, definimos:

$A_k = \sum_{i=1}^k \sigma_i u_i v_i^T,$

entonces se cumple $\| A - A_k \|_2 = \sigma_{k+1}$ y $\| A - A_k \|_F^2 = \sum_{i = k+1}^r \sigma_i^2$.

Este resultado se conoce como el **teorema de Eckart‚ÄìYoung**, y afirma que $A_k$ es la mejor aproximaci√≥n de $A$ por una matriz de rango $k$, en el sentido de ser la m√°s cercana seg√∫n dichas normas.


##### üìå Consecuencias pr√°cticas

- Los primeros t√©rminos de la SVD capturan la **estructura principal** de $A$.
- Los t√©rminos restantes pueden considerarse **ruido o detalles finos**.
- Este principio es la base de muchas t√©cnicas de **compresi√≥n**, **reducci√≥n de dimensionalidad** y **filtrado**.

Ejemplos t√≠picos incluyen:
- Representar im√°genes usando solo los primeros 10 valores singulares.
- Aproximar grandes matrices de datos con bajo rango efectivo.

"""

# ‚ïî‚ïê‚ï° dbb9e53d-bb68-4220-a32d-6c3ce32e274a
md"""
## Algoritmo de c√°lculo de la SVD

* **Opci√≥n 1**: $A^T A$
* * Definici√≥n
* * Por qu√© no se usa
* **Opci√≥n 2**: Desde el punto de vista num√©rico, **¬øc√≥mo se calcula esta descomposici√≥n sin formar $A^T A$?**
* * Intro
* * Fundamentos te√≥ricos
* * M√©todo de Golub‚ÄìKahan

## Comparaci√≥n / An√°lisis de los algoritmos
En la secci√≥n anterior vimos que la SVD de una matriz $A \in \mathbb{R}^{m \times n}$ (con $m \geq n$) tiene la forma:

$A = U \Sigma V^T,$

donde $U$ y $V$ son ortogonales, y $\Sigma$ es una matriz diagonal rectangular con entradas no negativas.

"""

# ‚ïî‚ïê‚ï° 85c6df45-20ef-4db2-8703-ddf76166832e
md"""
## Algoritmos de c√°lculo de la SVD

En esta secci√≥n abordamos el problema de c√≥mo calcular num√©ricamente la descomposici√≥n en valores singulares de una matriz $A \in \mathbb{R}^{m \times n}$. Aunque su existencia est√° garantizada te√≥ricamente, el c√°lculo efectivo de las matrices $U$, $\Sigma$ y $V$ requiere algoritmos cuidadosamente dise√±ados para asegurar estabilidad y eficiencia, especialmente cuando $A$ est√° mal condicionada o es de gran tama√±o.

Comenzamos con el algoritmo cl√°sico, que se basa en la relaci√≥n $A^T A = V \Sigma^2 V^T$ y permite obtener los valores y vectores singulares a partir de la descomposici√≥n espectral. Este m√©todo es √∫til para fines pedag√≥gicos, pero es num√©ricamente inadecuado debido a su sensibilidad a errores de redondeo.

Luego presentaremos el m√©todo de Golub‚ÄìKahan, que constituye la base de las implementaciones modernas de la SVD. Este enfoque evita formar $A^T A$ y combina una reducci√≥n bidiagonal mediante transformaciones ortogonales con una versi√≥n adaptada del algoritmo QR para matrices sim√©tricas. Analizaremos este m√©todo en tres partes: una introducci√≥n conceptual, los fundamentos te√≥ricos que lo justifican, y una descripci√≥n detallada del algoritmo.

Por √∫ltimo, exploraremos otras variantes relevantes como el m√©todo de Jacobi, los algoritmos divide-and-conquer, y algunas estrategias paralelas. Estas alternativas ofrecen ventajas particulares en t√©rminos de precisi√≥n o rendimiento, y permiten comparar diferentes enfoques bajo distintas condiciones computacionales.


### Algoritmo cl√°sico

#### üîπ Definici√≥n

Dada una matriz $A \in \mathbb{R}^{m \times n}$, el producto $A^T A$ es una matriz sim√©trica y semidefinida positiva de tama√±o $n \times n$. Sus autovalores son no negativos, y sus autovectores son precisamente los vectores singulares derechos de $A$.

Adem√°s, se cumple:

$A^T A = V \Sigma^2 V^T,$

lo que sugiere que una forma de obtener los valores singulares ser√≠a:

1. Formar $C = A^T A$,
2. Calcular sus autovalores $\lambda_i$,
3. Obtener $\sigma_i = \sqrt{\lambda_i}$,
4. Recuperar $U$ a partir de $AV = U \Sigma$.

#### üî∏ ¬øPor qu√© no se usa este enfoque?

Aunque conceptualmente sencilla, esta estrategia es **num√©ricamente inestable**:

- **P√©rdida de precisi√≥n:** el c√°lculo de $A^T A$ **cuadra la condici√≥n** de $A$:
  $\kappa_2(A^T A) = \kappa_2(A)^2,$
  lo que magnifica errores cuando $A$ es mal condicionada.

- **Cancelaciones destructivas:** en aritm√©tica de punto flotante, calcular $A^T A$ puede eliminar informaci√≥n valiosa contenida en $A$.

- **No preserva la estructura original:** operaciones como la bidiagonalizaci√≥n s√≠ preservan mejor las propiedades num√©ricas de $A$.

Por estas razones, los algoritmos modernos evitan formar expl√≠citamente $A^T A$, y utilizan en cambio m√©todos m√°s estables, como el de **Golub‚ÄìKahan**.


"""

# ‚ïî‚ïê‚ï° 74470dd1-eb43-4039-9d93-6bdf32768466
md"""
### M√©todo de Golub‚ÄìKahan

El algoritmo de Golub‚ÄìKahan para calcular la SVD de una matriz $A \in \mathbb{R}^{m \times n}$ (con $m \geq n$) consta de dos fases principales:

#### Paso a paso
##### üîπ Paso 1: Reducci√≥n bidiagonal

El primer paso transforma la matriz original $A$ en una matriz **bidiagonal** $B$, es decir, una matriz con ceros fuera de la diagonal y la superdiagonal:

$B = U_1^T A V_1$

Este paso se logra aplicando **transformaciones ortogonales de Householder** por la izquierda y la derecha, que eliminan progresivamente los elementos debajo de la diagonal y fuera de la banda bidiagonal.

La estructura resultante tiene la forma:

$B = \begin{bmatrix}
d_1 & f_1 &        &        & \\
    & d_2 & f_2    &        & \\
    &     & \ddots & \ddots & \\
    &     &        & d_{n-1} & f_{n-1} \\
    &     &        &        & d_n
\end{bmatrix}$

Donde $d_i$ son los elementos diagonales y $f_i$ los elementos de la superdiagonal.

Este paso convierte el problema general en uno estructurado, sin alterar los valores singulares, y adem√°s **preserva la estabilidad num√©rica**.

##### üîπ Paso 2: Diagonalizaci√≥n bidiagonal (iteraci√≥n QR sim√©trica)

Una vez reducida $A$ a bidiagonal, el siguiente objetivo es transformar $B$ en una matriz **diagonal**, es decir, eliminar su superdiagonal sin perturbar la estructura.

Para esto se emplea una versi√≥n adaptada del **algoritmo QR sim√©trico con desplazamiento**. En lugar de formar $B^T B$ (que ser√≠a tridiagonal), se trabaja directamente sobre $B$ aplicando secuencias de **rotaciones de Givens** que eliminan progresivamente los elementos $f_i$.

Cada iteraci√≥n consta de:

1. C√°lculo de un **desplazamiento (shift)** aproximado del valor singular, basado en el extremo de la banda bidiagonal.
2. Aplicaci√≥n de rotaciones alternadas por la derecha e izquierda (tipo QR sim√©trico impl√≠cito) para "empujar" el elemento fuera de banda hacia la esquina inferior.
3. Eliminaci√≥n (o reducci√≥n por deflaci√≥n) cuando alg√∫n $f_i$ es suficientemente peque√±o en magnitud.

Este proceso se repite hasta que toda la superdiagonal de $B$ se anula, y la matriz resultante se convierte en la matriz $\Sigma$ de la SVD. Las rotaciones aplicadas se acumulan en matrices ortogonales $U_2$ y $V_2$.


##### üîπ Paso 3: Composici√≥n final

Finalmente, la SVD completa de $A$ se reconstruye a partir de las transformaciones aplicadas:

$A = U \Sigma V^T, \quad \text{donde } U = U_1 U_2,\quad V = V_1 V_2$

En esta descomposici√≥n:
- la matriz $\Sigma$ es una matriz diagonal con los valores singulares ordenados,
- las matrices $U$ y $V$ son ortogonales, y
- el proceso es **estable**, ya que todas las operaciones se realizan con transformaciones ortogonales.

"""

# ‚ïî‚ïê‚ï° 247c0f32-0141-424f-9e8d-6dda19a521db
md"""
#### ü§ñ Implementaci√≥n

Supuestos:

* La matriz $B$ es **bidiagonal superior**: solo tiene elementos en la diagonal $d$ y superdiagonal $f$.
* No se acumulan rotaciones (esto puede a√±adirse).
* El paso trabaja **in-place** sobre los vectores `d` y `f`.

Notas:

* Esta implementaci√≥n **modifica `d` y `f` in-place**.
* No acumula las transformaciones $U$ y $V$, pero eso puede a√±adirse si se desea formar expl√≠citamente las matrices singulares.
* El desplazamiento de Wilkinson garantiza una buena convergencia, especialmente cerca del valor singular m√°s peque√±o.

"""

# ‚ïî‚ïê‚ï° 3d76d8e3-fa4a-4e88-81cd-7489cdb146d7
md"##### üëæ Desplazamiento de Wilkinson"

# ‚ïî‚ïê‚ï° d5e98c9e-92ee-454d-9de8-7c5f38e89c68
"""
Calcula el shift de Wilkinson (mu) a partir de los tres elementos finales de B bidiagonal.

Inputs:
- dm: elemento d_{n-1} (pen√∫ltimo de la diagonal)
- fm: elemento f_{n-1} (√∫ltimo de la superdiagonal)
- dn: elemento d_n (√∫ltimo de la diagonal)

Output:
- mu: shift de Wilkinson
"""
function wilkinson_shift(dm::Float64, fm::Float64, dn::Float64)
    tmm = dm^2 + fm^2
    tmn = fm * dn
    tnn = dn^2

    Œ¥ = (tmm - tnn) / 2
    denom = abs(Œ¥) + sqrt(Œ¥^2 + tmn^2)

    if denom == 0
        return tnn
    else
        return tnn - sign(Œ¥) * tmn^2 / denom
    end
end


# ‚ïî‚ïê‚ï° 8ca30862-249a-444d-8a79-702ec8732935
"""
Compara `wilkinson_shift` con el verdadero autovalor de una matriz 2x2 para validar.
"""
function validate_shift(dm, fm, dn)
    T = [
        dm^2 + fm^2    fm * dn
        fm * dn        dn^2
    ]
    Œª = eigen(T).values
    Œº_ref = Œª[argmin(abs.(Œª .- dn^2))]  # autovalor m√°s cercano a t_nn
    Œº_custom = wilkinson_shift(dm, fm, dn)
    
    println("Œº (eigen 2√ó2)     = $Œº_ref")
    println("Œº (Wilkinson calc)= $Œº_custom")
    println("Error             = $(abs(Œº_custom - Œº_ref))")
end


# ‚ïî‚ïê‚ï° e9b5e9ee-83ae-41e0-b5cd-d7772d95d27b
validate_shift(3.0, 0.01, 4.0)

# ‚ïî‚ïê‚ï° 906732db-6348-495d-909c-017bbc036659
validate_shift(1.0, 0.5, 1.2)

# ‚ïî‚ïê‚ï° 1740f53a-0e59-4fa7-b63e-e74c0b8bb484
md"##### üëæ Rotaciones de Givens"

# ‚ïî‚ïê‚ï° 7902449e-e1ca-4dd7-aef1-96d32e051f40
"""
Devuelve (c, s, r) tal que [c s; -s c] * [y; z] = [r; 0]
"""
function givens_rotation(y::Float64, z::Float64)
    if z == 0
        return (1.0, 0.0, y)
    elseif y == 0
        return (0.0, 1.0, z)
    else
        r = hypot(y, z)
        return (y / r, z / r, r)
    end
end


# ‚ïî‚ïê‚ï° d79631a6-4494-49bd-a9e5-8b100de0272d
"""
Aplica rotaci√≥n de Givens por la derecha sobre d[k] y f[k]
"""
function apply_right_rotation!(d, f, k::Int, c::Float64, s::Float64)
    d_k  = d[k]
    f_k  = f[k]
    d[k] =  c * d_k + s * f_k
    f[k] = -s * d_k + c * f_k
end


# ‚ïî‚ïê‚ï° 2edc23a7-b981-4416-8516-54084054bd74
"""
Aplica rotaci√≥n de Givens por la izquierda sobre d[k] y d[k+1]
"""
function apply_left_rotation!(d, k::Int, c::Float64, s::Float64)
    d_k  = d[k]
    d_k1 = d[k+1]
    d[k]   =  c * d_k + s * d_k1
    d[k+1] = -s * d_k + c * d_k1
end


# ‚ïî‚ïê‚ï° c0d5d51b-09c8-407a-8169-bd8937545954
md"##### üëæ Paso de Golub-Kahan"

# ‚ïî‚ïê‚ï° c2105a86-9dda-4ccb-a9df-cba3c10b6161
"""
Construye una matriz bidiagonal superior B ‚àà ‚Ñù^{n√ón} a partir de:

- d: diagonal de B, longitud n
- f: superdiagonal de B, longitud n - 1

Retorna: B :: Matrix{Float64}, una matriz n√ón con estructura bidiagonal superior.
"""
function build_bidiagonal(d, f)
    n = length(d)
    @assert length(f) == n - 1 "La superdiagonal f debe tener longitud n - 1"

    B = zeros(Float64, n, n)

    for i in 1:n
        B[i, i] = d[i]
        if i < n
            B[i, i+1] = f[i]
        end
    end

    return B
end


# ‚ïî‚ïê‚ï° a1c28c45-10de-460c-909f-ab724f2afd45
"""
Valida un paso de Golub‚ÄìKahan aplicado a una matriz bidiagonal B.

- step_func: funci√≥n que modifica B in-place (como golub_kahan_svd_step_matrix!)
- B: matriz bidiagonal cuadrada (con solo diagonal y superdiagonal)

Opcional:
- verbose = true: imprime detalles
- atol: tolerancia para comparar autovalores

Retorna: true si todo pasa, false si falla alguna prueba.
"""
function validate_golub_kahan_step(step_func::Function, B::Matrix{Float64};
                                   atol=1e-10, verbose=true)
    n = size(B, 1)
    @assert size(B, 2) == n "B debe ser cuadrada"

    # --- Copiar datos originales ---
    B_before = copy(B)
    T_before = B_before' * B_before
    Œª_before = sort(eigvals(Symmetric(T_before)))

    # --- Aplicar paso QR bidiagonal ---
    step_func(B)

    # --- Verificar estructura bidiagonal ---
    is_bidiagonal = all(i == j || j == i+1 || B[i, j] == 0.0 for i in 1:n, j in 1:n)

    # --- Comparar autovalores ---
    T_after = B' * B
    Œª_after = sort(eigvals(Symmetric(T_after)))
    Œª_diff = norm(Œª_before - Œª_after, Inf)

    # --- Imprimir si se desea ---
    if verbose
        println("‚úî Estructura bidiagonal: ", is_bidiagonal)
        println("‚úî Autovalores antes:  ", round.(Œª_before, digits=8))
        println("‚úî Autovalores despu√©s:", round.(Œª_after, digits=8))
        println("ŒîŒª ‚àû-norm: ", Œª_diff)
    end

    return is_bidiagonal && Œª_diff ‚â§ atol
end


# ‚ïî‚ïê‚ï° fd6ebedb-0a06-4675-adb2-7076f96fe25b
md"###### üëæ Versi√≥n impl√≠cita"

# ‚ïî‚ïê‚ï° 9a929fc1-a2b2-474a-9deb-4d8a6bc6d7d1
function golub_kahan_svd_step!(d::Vector{Float64}, f::Vector{Float64})
    n = length(d)
    @assert length(f) == n - 1

    if n < 2
        return d, f
    end

    # --- Paso 1: calcular el shift de Wilkinson ---
    Œº = wilkinson_shift(d[end-1], f[end], d[end])

    # --- Paso 2: inicializar el bulge ---
    x = d[1]^2 - Œº
    z = d[1] * f[1]

    for k in 1:n-1
        # --- Rotaci√≥n por la derecha: columnas k, k+1 ---
        c, s, _ = givens_rotation(x, z)

        d_k   = d[k]
        f_k   = f[k]
        d_kp1 = d[k+1]

        # Actualizar d[k] y f[k]
        d[k] =  c * d_k + s * f_k
        f[k] = -s * d_k + c * f_k

        # Crear bulge en d[k+1]
        x = d[k]
        z = d_kp1

        # --- Rotaci√≥n por la izquierda: filas k, k+1 ---
        c, s, _ = givens_rotation(x, z)

        d[k]     =  c * x + s * z
        d[k+1]   = -s * x + c * z

        # Actualizar f[k] y f[k+1] si no es el √∫ltimo paso
        if k < n - 1
            f_kp1 = f[k+1]
            x = f[k]
            z = f_kp1
            c, s, _ = givens_rotation(x, z)
            f[k]   =  c * x + s * z
            f[k+1] = 0.0  # bulge eliminado
        end
    end

    return d, f
end


# ‚ïî‚ïê‚ï° 9cd5e17f-721a-4b99-bd80-db95a1ef99f0
begin
	golub_kahan_svd_step!([4.0, 3.0, 2.0] , [1.0, 0.5])
	golub_kahan_svd_step!([1.0, 2.0, 3.0, 4.0] , [1.0, 1.0, 0.01])
end

# ‚ïî‚ïê‚ï° 8065ba2c-c0ce-4cc8-87d2-e98fad2868a3
begin
	d = [3.0, 2.0, 1.0]
	f = [0.5, 0.3]
	
	validate_golub_kahan_step(d, f)
	
end

# ‚ïî‚ïê‚ï° 004da5d0-d039-4f0c-890b-16cdf36d21f9
md"###### üëæ Versi√≥n expl√≠cita"

# ‚ïî‚ïê‚ï° adba5d98-0080-4d56-81ca-897d8a97eb39
"""
Aplica un paso QR bidiagonal de Golub‚ÄìKahan a una matriz bidiagonal superior B ‚àà ‚Ñù^{n√ón}.

- B debe tener solo elementos en la diagonal y superdiagonal.
- La estructura bidiagonal se preserva.
- La transformaci√≥n es ortogonal y mantiene aproximadamente los autovalores de B·µóB.

Modifica B in-place.
"""
function golub_kahan_svd_step_matrix!(B::Matrix{Float64})
    n = size(B, 1)
    @assert size(B, 2) == n

    # Calcular el shift de Wilkinson
    d = diag(B)
    f = [B[i, i+1] for i in 1:n-1]
    Œº = wilkinson_shift(d[end-1], f[end], d[end])

    # Inicializar el primer vector para la rotaci√≥n por la derecha
    y = d[1]^2 - Œº
    z = d[1] * B[1, 2]

    for k in 1:n-1
        # -------- Rotaci√≥n por la derecha (columnas k, k+1) --------
        c, s, _ = givens_rotation(y, z)

        # Solo columnas k y k+1 de filas k y siguientes (preservar estructura)
        for i in k:n
            t1 = B[i, k]
            t2 = B[i, k+1]
            B[i, k]   =  c * t1 + s * t2
            B[i, k+1] = -s * t1 + c * t2
        end

        # -------- Rotaci√≥n por la izquierda (filas k, k+1) --------
        y = B[k, k]
        z = B[k+1, k]
        c, s, _ = givens_rotation(y, z)

        # Solo filas k y k+1 de columnas k y siguientes
        for j in k:n
            t1 = B[k, j]
            t2 = B[k+1, j]
            B[k, j]   =  c * t1 + s * t2
            B[k+1, j] = -s * t1 + c * t2
        end

        # Preparar vector (y, z) para la pr√≥xima rotaci√≥n por la derecha
        if k < n - 1
            y = B[k, k+1]
            z = B[k, k+2]
        end
    end

    # Limpiar num√©ricamente la matriz fuera de la banda bidiagonal
    for i in 1:n
        for j in 1:n
            if j ‚â† i && j ‚â† i+1
                B[i, j] = 0.0
            end
        end
    end

    return B
end


# ‚ïî‚ïê‚ï° 2607c879-d632-4b80-8523-123221a01303
begin
	golub_kahan_svd_step_matrix!(build_bidiagonal([4.0, 3.0, 2.0] , [1.0, 0.5]))
	golub_kahan_svd_step_matrix!(build_bidiagonal([1.0, 2.0, 3.0, 4.0] , [1.0, 1.0, 0.01]))
end

# ‚ïî‚ïê‚ï° 8ec72b94-d090-4c76-bde4-70787a67461a
begin
	B = build_bidiagonal([1.0, 2.0, 3.0, 4.0], [1.0, 1.0, 0.01])
	
	validate_golub_kahan_step(golub_kahan_svd_step_matrix!, B)
end

# ‚ïî‚ïê‚ï° 5bd0c109-17c9-4e93-bdfb-e8faf660f708
md"##### üëæ Algoritmo de Golub-Kahan"

# ‚ïî‚ïê‚ï° b2928cde-9e9b-4d28-8a0a-45bae8e8f4ef
"""
Aplica el algoritmo completo de Golub‚ÄìKahan para diagonalizar una matriz bidiagonal.

Input:
- d: Vector{Float64} con la diagonal de la matriz bidiagonal B
- f: Vector{Float64} con la superdiagonal de B
- œµ: Tolerancia (por defecto, 100√óeps(Float64))

Output:
- d: Diagonal actualizada (valores singulares)
- f: Superdiagonal (debe terminar cercana a cero)
"""
function golub_kahan_svd!(d::Vector{Float64}, f::Vector{Float64}; œµ = 100 * eps(Float64))
    n = length(d)
    @assert length(f) == n - 1

    # Ciclo externo: repetir hasta que todos los f[i] sean peque√±os
    while true
		display(f)
		display(d)
        # Paso 1: forzar ceros peque√±os en f por deflaci√≥n
        for i in 1:n-1
            tol = œµ * (abs(d[i]) + abs(d[i+1]))
            if abs(f[i]) ‚â§ tol
                f[i] = 0.0
            end
        end

        # Paso 2: buscar submatrices no diagonales
        # Buscar el mayor √≠ndice q tal que f[q] ‚â† 0
        q = n
        while q > 1 && f[q-1] == 0.0
            q -= 1
        end

        # Si ya no queda banda activa, terminar
        if q == 1
            break
        end

        # Buscar el menor p tal que f[p] ‚â† 0
        p = q - 1
        while p > 1 && f[p-1] ‚â† 0.0
            p -= 1
        end

        # Verificar si hay ceros en la diagonal de B_{p:q}
        zero_on_diag = false
        for i in p:q
            if abs(d[i]) ‚â§ œµ * maximum(abs.(d))
                zero_on_diag = true
                break
            end
        end

        if zero_on_diag
            # Si hay ceros en la diagonal, hacer cero la fila correspondiente
            for i in p:q-1
                if abs(d[i]) ‚â§ œµ * maximum(abs.(d))
                    f[i] = 0.0
                end
            end
        elseif q - p + 1 >= 2
            # Aplicar un paso QR bidiagonal al bloque activo d[p:q], f[p:q-1]
            dblock = view(d, p:q)
            fblock = view(f, p:q-1)
            golub_kahan_svd_step_matrix!(build_bidiagonal(dblock, fblock))
        end
    end

    return d
end


# ‚ïî‚ïê‚ï° 7c84c4d6-27fc-4c78-9002-eeb6b8780272
#golub_kahan_svd!([4.0, 3.0, 2.0], [1.0, 0.5])
	
# Resultado: `d` contiene los valores singulares aproximados de la matriz bidiagonal

# ‚ïî‚ïê‚ï° 00ca8f64-6937-45ee-8970-d1c2bf49fd59
md"
To Do:
- [ ] Add other implementation (either classical or Jacobi)
- [ ] Have a working Golub

"

# ‚ïî‚ïê‚ï° 00000000-0000-0000-0000-000000000001
PLUTO_PROJECT_TOML_CONTENTS = """
[deps]
LinearAlgebra = "37e2e46d-f89d-539d-b4ee-838fcccc9c8e"
"""

# ‚ïî‚ïê‚ï° 00000000-0000-0000-0000-000000000002
PLUTO_MANIFEST_TOML_CONTENTS = """
# This file is machine-generated - editing it directly is not advised

julia_version = "1.11.1"
manifest_format = "2.0"
project_hash = "ac1187e548c6ab173ac57d4e72da1620216bce54"

[[deps.Artifacts]]
uuid = "56f22d72-fd6d-98f1-02f0-08ddc0907c33"
version = "1.11.0"

[[deps.CompilerSupportLibraries_jll]]
deps = ["Artifacts", "Libdl"]
uuid = "e66e0078-7015-5450-92f7-15fbd957f2ae"
version = "1.1.1+0"

[[deps.Libdl]]
uuid = "8f399da3-3557-5675-b5ff-fb832c97cbdb"
version = "1.11.0"

[[deps.LinearAlgebra]]
deps = ["Libdl", "OpenBLAS_jll", "libblastrampoline_jll"]
uuid = "37e2e46d-f89d-539d-b4ee-838fcccc9c8e"
version = "1.11.0"

[[deps.OpenBLAS_jll]]
deps = ["Artifacts", "CompilerSupportLibraries_jll", "Libdl"]
uuid = "4536629a-c528-5b80-bd46-f80d51c5b363"
version = "0.3.27+1"

[[deps.libblastrampoline_jll]]
deps = ["Artifacts", "Libdl"]
uuid = "8e850b90-86db-534c-a0d3-1478176c7d93"
version = "5.11.0+0"
"""

# ‚ïî‚ïê‚ï° Cell order:
# ‚ïü‚îÄa58e9c22-51a1-11f0-0fc0-914efb421b18
# ‚ï†‚ïê701241c2-322f-45ca-b17d-437cf32a7ff3
# ‚ïü‚îÄ11b2ebb7-626e-49c1-a294-c9b834c73bdb
# ‚ïü‚îÄ6b68d0ac-8118-44aa-940e-5a807217e562
# ‚ïü‚îÄ56ef11c7-1b71-45f7-b286-38a932ac3dc4
# ‚ïü‚îÄdbb9e53d-bb68-4220-a32d-6c3ce32e274a
# ‚ïü‚îÄ85c6df45-20ef-4db2-8703-ddf76166832e
# ‚ïü‚îÄ74470dd1-eb43-4039-9d93-6bdf32768466
# ‚ïü‚îÄ247c0f32-0141-424f-9e8d-6dda19a521db
# ‚ïü‚îÄ3d76d8e3-fa4a-4e88-81cd-7489cdb146d7
# ‚ïü‚îÄd5e98c9e-92ee-454d-9de8-7c5f38e89c68
# ‚ïü‚îÄ8ca30862-249a-444d-8a79-702ec8732935
# ‚ï†‚ïêe9b5e9ee-83ae-41e0-b5cd-d7772d95d27b
# ‚ï†‚ïê906732db-6348-495d-909c-017bbc036659
# ‚ïü‚îÄ1740f53a-0e59-4fa7-b63e-e74c0b8bb484
# ‚ïü‚îÄ7902449e-e1ca-4dd7-aef1-96d32e051f40
# ‚ïü‚îÄd79631a6-4494-49bd-a9e5-8b100de0272d
# ‚ïü‚îÄ2edc23a7-b981-4416-8516-54084054bd74
# ‚ïü‚îÄc0d5d51b-09c8-407a-8169-bd8937545954
# ‚ïü‚îÄc2105a86-9dda-4ccb-a9df-cba3c10b6161
# ‚ïü‚îÄa1c28c45-10de-460c-909f-ab724f2afd45
# ‚ïü‚îÄfd6ebedb-0a06-4675-adb2-7076f96fe25b
# ‚ïü‚îÄ9a929fc1-a2b2-474a-9deb-4d8a6bc6d7d1
# ‚ï†‚ïê9cd5e17f-721a-4b99-bd80-db95a1ef99f0
# ‚ï†‚ïê8065ba2c-c0ce-4cc8-87d2-e98fad2868a3
# ‚ïü‚îÄ004da5d0-d039-4f0c-890b-16cdf36d21f9
# ‚ï†‚ïêadba5d98-0080-4d56-81ca-897d8a97eb39
# ‚ï†‚ïê2607c879-d632-4b80-8523-123221a01303
# ‚ï†‚ïê8ec72b94-d090-4c76-bde4-70787a67461a
# ‚ïü‚îÄ5bd0c109-17c9-4e93-bdfb-e8faf660f708
# ‚ï†‚ïêb2928cde-9e9b-4d28-8a0a-45bae8e8f4ef
# ‚ï†‚ïê7c84c4d6-27fc-4c78-9002-eeb6b8780272
# ‚ï†‚ïê00ca8f64-6937-45ee-8970-d1c2bf49fd59
# ‚ïü‚îÄ00000000-0000-0000-0000-000000000001
# ‚ïü‚îÄ00000000-0000-0000-0000-000000000002
